{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Slack Community</a>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to use AX Datasts & Experiments to systematically evaluate and improve AI agents. You'll learn how to create datasets, define task functions that run your agent on each example, and use both code-based and LLM-as-a-Judge evaluators to measure performance. By the end, you'll be able to run experiments that compare different agent versions and track improvements over time, enabling data-driven development and deployment decisions.\n",
    "\n",
    "The notebook covers four main sections. Follow the documention for the complete tutorial.\n",
    "\n",
    "\n",
    "*   **Define Agent**: Set up a customer support agent with tools for ticket classification and policy retrieval, using the agno framework labels, then upload it to Phoenix\n",
    "*   **Create a Dataset**: Build a dataset of support ticket queries with ground truth labels, then upload it to Phoenix\n",
    "*   **Define an Experiment**: Create task functions and evaluators (code-based and LLM judges), then run experiments to measure agent performance and compare different versions\n",
    "*   **Iterations with Experiments**: Compare different agent versions using experiments to validate improvements before deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agno arize[otel] anthropic openinference-instrumentation-agno openinference-instrumentation-anthropic arize-phoenix-evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-api-key\"\n",
    "os.environ[\"ARIZE_API_KEY\"] = \"your-arize-api-key\"\n",
    "os.environ[\"ARIZE_SPACE_ID\"] = \"your-arize-space-id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arize.otel import register\n",
    "from openinference.instrumentation.anthropic import AnthropicInstrumentor\n",
    "from openinference.instrumentation.agno import AgnoInstrumentor\n",
    "\n",
    "tracer_provider = register(\n",
    "    space_id=os.getenv(\"ARIZE_SPACE_ID\"),\n",
    "    api_key=os.getenv(\"ARIZE_API_KEY\"),\n",
    "    project_name=\"experiments-tutorial\",\n",
    ")\n",
    "AnthropicInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "AgnoInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Support Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This agent is a customer support assistant that helps users resolve their issues by classifying tickets and retrieving relevant policies. The agent has two tools: `classify_ticket`, which categorizes support tickets into billing, technical, account, or other categories, and `retrieve_policy`, which fetches the appropriate internal support policy based on the ticket category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.models.anthropic import Claude\n",
    "from agno.tools import tool\n",
    "from anthropic import Anthropic\n",
    "\n",
    "CATEGORIES = [\"billing\", \"technical\", \"account\", \"other\"]\n",
    "\n",
    "anthropic_client = Anthropic()\n",
    "\n",
    "\n",
    "@tool\n",
    "def classify_ticket(ticket_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify a support ticket into:\n",
    "    billing, technical, account, or other.\n",
    "    \"\"\"\n",
    "\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-sonnet-4-5-20250929\",\n",
    "        max_tokens=50,\n",
    "        system=(\n",
    "            \"You classify customer support tickets into one of the \"\n",
    "            \"following categories: billing, technical, account, other. \"\n",
    "            \"Respond with ONLY the category name.\"\n",
    "        ),\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": ticket_text,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    label = response.content[0].text.strip().lower()\n",
    "\n",
    "    if label not in CATEGORIES:\n",
    "        return \"other\"\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLICIES = {\n",
    "    \"billing\": \"Billing policy: Refunds are issued for duplicate charges within 7 days.\",\n",
    "    \"technical\": \"Technical policy: Troubleshoot login issues, outages, and errors.\",\n",
    "    \"account\": \"Account policy: Users can update email and password in account settings.\",\n",
    "    \"other\": \"General support policy: Route to a human agent.\",\n",
    "}\n",
    "\n",
    "\n",
    "@tool\n",
    "def retrieve_policy(category: str) -> str:\n",
    "    \"\"\"Retrieve internal support policy.\"\"\"\n",
    "    return POLICIES.get(category, POLICIES[\"other\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.agent import Agent\n",
    "\n",
    "support_agent = Agent(\n",
    "    name=\"SupportAgent\",\n",
    "    model=Claude(id=\"claude-sonnet-4-5-20250929\"),\n",
    "    tools=[classify_ticket, retrieve_policy],\n",
    "    instructions=\"\"\"\n",
    "You are a customer support assistant.\n",
    "\n",
    "Steps:\n",
    "1. Use classify_ticket to determine the issue category.\n",
    "2. Use retrieve_policy to fetch the relevant policy.\n",
    "3. Write a helpful, polite response grounded in the policy.\n",
    "Do not invent policies.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tickets = [\n",
    "    \"I was charged twice for my subscription this month.\",\n",
    "    \"My app crashes every time I try to log in.\",\n",
    "    \"How do I change the email on my account?\",\n",
    "    \"This product is terrible and nothing works.\",\n",
    "]\n",
    "\n",
    "for ticket in sample_tickets:\n",
    "    support_agent.run(ticket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    {\"query\": \"I was charged twice for my subscription this month.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"My app crashes every time I try to log in.\", \"expected_category\": \"technical\"},\n",
    "    {\"query\": \"How do I change the email on my account?\", \"expected_category\": \"account\"},\n",
    "    {\"query\": \"I want a refund because I was billed incorrectly.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"The website shows a 500 error.\", \"expected_category\": \"technical\"},\n",
    "    {\"query\": \"I forgot my password and cannot sign in.\", \"expected_category\": \"account\"},\n",
    "    {\"query\": \"I was billed after canceling my subscription.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"The app freezes on startup.\", \"expected_category\": \"technical\"},\n",
    "    {\"query\": \"How can I update my billing address?\", \"expected_category\": \"account\"},\n",
    "    {\"query\": \"Why was my credit card charged twice?\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"Push notifications are not working.\", \"expected_category\": \"technical\"},\n",
    "    {\"query\": \"Can I change my username?\", \"expected_category\": \"account\"},\n",
    "    {\"query\": \"I was charged even though my trial should be free.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"The page won’t load on mobile.\", \"expected_category\": \"technical\"},\n",
    "    {\"query\": \"How do I delete my account?\", \"expected_category\": \"account\"},\n",
    "    {\"query\": \"I canceled last week but still see a pending charge and now the app won’t open.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"Nothing works anymore and I don’t even know where to start.\", \"expected_category\": \"other\"},\n",
    "    {\"query\": \"I updated my email and now I can’t log in — also was billed today.\", \"expected_category\": \"account\"},\n",
    "    {\"query\": \"This service is unusable and I want my money back.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"I think something is wrong with my account but support never responds.\", \"expected_category\": \"account\"},\n",
    "    {\"query\": \"My subscription status looks wrong and the app crashes randomly.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"Why am I being charged if I can’t access my account?\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"The app broke after the last update and now billing looks incorrect.\", \"expected_category\": \"technical\"},\n",
    "    {\"query\": \"I’m locked out and still getting charged — please help.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"This feels like both a billing and technical issue.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"Everything worked yesterday, today nothing does.\", \"expected_category\": \"technical\"},\n",
    "    {\"query\": \"I don’t recognize this charge and the app won’t load.\", \"expected_category\": \"billing\"},\n",
    "    {\"query\": \"Account settings changed on their own and I was billed.\", \"expected_category\": \"account\"},\n",
    "    {\"query\": \"I want to cancel but can’t log in.\", \"expected_category\": \"account\"},\n",
    "    {\"query\": \"The system is broken and I’m losing money.\", \"expected_category\": \"billing\"},\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "dataset_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Dataset\n",
    "\n",
    "from arize import ArizeClient\n",
    "\n",
    "client = ArizeClient(api_key= os.getenv(\"ARIZE_API_KEY\"))\n",
    "\n",
    "dataset = client.datasets.create(\n",
    "    name=\"support-ticket-queries\",\n",
    "    space_id= os.getenv(\"ARIZE_SPACE_ID\"),\n",
    "    examples=dataset_df,\n",
    ")\n",
    "dataset_id = dataset.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Define an Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an Experiment to Check Tool Call Accuracy (Code-Based Evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our tool function from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ticket_fn(ticket_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify a support ticket into:\n",
    "    billing, technical, account, or other.\n",
    "    \"\"\"\n",
    "    if isinstance(ticket_text, dict):\n",
    "        ticket_text = ticket_text.get(\"query\", str(ticket_text))\n",
    "\n",
    "    ticket_text = str(ticket_text)\n",
    "\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-sonnet-4-5-20250929\",\n",
    "        max_tokens=50,\n",
    "        system=(\n",
    "            \"You classify customer support tickets into one of the \"\n",
    "            \"following categories: billing, technical, account, other. \"\n",
    "            \"Respond with ONLY the category name.\"\n",
    "        ),\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": ticket_text,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    label = response.content[0].text.strip().lower()\n",
    "\n",
    "    if label not in CATEGORIES:\n",
    "        return \"other\"\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ticket_task(input):\n",
    "    \"\"\"\n",
    "    Task used specifically for evaluating tool call accuracy.\n",
    "    \"\"\"\n",
    "    query = input.get(\"query\")\n",
    "    classification = classify_ticket(query)\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our \"baseline\" examples have a ground truth field, we can used a code based evaluator to check if the task output matches what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Code-Based Evaluator for Tool Call Accuracy\n",
    "from arize.experiments import EvaluationResult\n",
    "\n",
    "def tool_call_accuracy(output, dataset_row) -> bool:\n",
    "    \"\"\"\n",
    "    Code-based evaluator that checks if the classify_ticket tool output\n",
    "    matches the expected category from the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    expected_category = dataset_row.get(\"expected_category\")\n",
    "    score = output.strip().lower() == expected_category\n",
    "\n",
    "    return EvaluationResult(\n",
    "        score=1.0 if score else 0.0,\n",
    "        label=\"correct\" if score else \"incorrect\",\n",
    "        explanation = \"correct\" if score else \"incorrect\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment, experiment_df = client.experiments.run(\n",
    "    name=\"tool call experiment\",\n",
    "    dataset_id=dataset_id,\n",
    "    task=classify_ticket_fn,\n",
    "    evaluators=[tool_call_accuracy],  # Pass your evaluator(s) here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an Experiment to Understand Overall Agent Performance (LLM-as-a-Judge Evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_agent_task(dataset_row):\n",
    "    \"\"\"\n",
    "    Task function that will be run on each row of the dataset.\n",
    "    \"\"\"\n",
    "    query = dataset_row.get(\"query\")\n",
    "\n",
    "    # Call the agent with the query\n",
    "    response = support_agent.run(query)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM Judge Evaluator checking for Actionable Responses\n",
    "from phoenix.evals import LLM, create_classifier\n",
    "from arize.experiments import EvaluationResult\n",
    "\n",
    "# Define Prompt Template\n",
    "support_response_actionability_judge = \"\"\"\n",
    "You are evaluating a customer support agent's response.\n",
    "\n",
    "Determine whether the response is ACTIONABLE and helps resolve the user's issue.\n",
    "\n",
    "Mark the response as CORRECT if it:\n",
    "- Directly addresses the user's specific question\n",
    "- Provides concrete steps, guidance, or information\n",
    "- Clearly routes the user toward a solution\n",
    "\n",
    "Mark the response as INCORRECT if it:\n",
    "- Is generic, vague, or non-specific\n",
    "- Avoids answering the question\n",
    "- Provides no clear next steps\n",
    "- Deflects with phrases like \"contact support\" without guidance\n",
    "\n",
    "User Query:\n",
    "{input}\n",
    "\n",
    "Agent Response:\n",
    "{output}\n",
    "\n",
    "Return only one label: \"correct\" or \"incorrect\".\n",
    "\"\"\"\n",
    "\n",
    "# Create Evaluator using a different Anthropic model than the agent\n",
    "actionability_judge = create_classifier(\n",
    "    name=\"actionability-judge\",\n",
    "    prompt_template=support_response_actionability_judge,\n",
    "    llm=LLM(model=\"claude-3-5-haiku-20241022\", provider=\"anthropic\"),\n",
    "    choices={\"correct\": 1.0, \"incorrect\": 0.0},\n",
    ")\n",
    "\n",
    "\n",
    "def call_actionability_judge(dataset_row, output):\n",
    "    \"\"\"\n",
    "    Wrapper function for the actionability judge evaluator.\n",
    "    This is needed because run_experiment expects a function, not an evaluator object.\n",
    "    \"\"\"\n",
    "    results = actionability_judge.evaluate({\"input\": dataset_row.get(\"query\"), \"output\": output})\n",
    "    result = results[0]\n",
    "    return EvaluationResult(score=result.score, label=result.label, explanation=result.explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment, experiment_df = client.experiments.run(\n",
    "    name=\"support agent performance\",\n",
    "    dataset_id=dataset_id,\n",
    "    task= support_agent_task,\n",
    "    evaluators=[call_actionability_judge],  # Pass your evaluator(s) here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI/CD with Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Agent with Better Actionability\n",
    "# This version has enhanced instructions to improve actionability scores\n",
    "\n",
    "improved_support_agent = Agent(\n",
    "    name=\"SupportAgent\",\n",
    "    model=Claude(id=\"claude-sonnet-4-5-20250929\"),\n",
    "    tools=[classify_ticket, retrieve_policy],\n",
    "    instructions=\"\"\"\n",
    "You are a customer support assistant. Your goal is to provide SPECIFIC, ACTIONABLE responses that directly help users resolve their issues.\n",
    "\n",
    "1. Use classify_ticket to determine the issue category.\n",
    "2. Use retrieve_policy to fetch the relevant policy.\n",
    "3. Write a response that:\n",
    "   - Directly addresses the user's specific question\n",
    "   - Includes the policy information you retrieved\n",
    "   - Provides clear, concrete next steps the user can take\n",
    "   - Uses specific details from the policy (e.g., \"within 7 days\" not \"soon\")\n",
    "   - Avoids vague phrases like \"should be able to\" or \"might be able to\"\n",
    "   - Gives actionable guidance (ex: \"Go to Settings > Account > Email\" not \"check your settings\")\n",
    "\n",
    "Example of GOOD response:\n",
    "\"Based on your billing issue, here's what you can do: Refunds are issued for duplicate charges within 7 days. To request your refund, please [specific action]. You should see the refund processed within 7 business days.\"\n",
    "\n",
    "Example of BAD response:\n",
    "\"I understand your concern about billing. Please contact our support team for assistance with this matter.\"\n",
    "\n",
    "Do not invent policies. Always use the policy information from retrieve_policy.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task function using the improved agent\n",
    "def improved_support_agent_task(dataset_row):\n",
    "    \"\"\"\n",
    "    Task function using the improved agent with better actionability instructions.\n",
    "    \"\"\"\n",
    "    query = dataset_row.get(\"query\")\n",
    "    response = improved_support_agent.run(query)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment with improved agent to compare actionability scores\n",
    "\n",
    "improved_experiment, improved_experiment_df = client.experiments.run(\n",
    "    name=\"support agent performance with improved prompt\",\n",
    "    dataset_id=dataset_id,\n",
    "    task= improved_support_agent_task,\n",
    "    evaluators=[call_actionability_judge],  # Pass your evaluator(s) here\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
