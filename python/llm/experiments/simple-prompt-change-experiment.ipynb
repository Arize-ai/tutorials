{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3G1ZIqkX9On"
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Slack Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "# Using Arize with Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEKy__ti95Bs"
   },
   "source": [
    "This guide demonstrates how to use Arize for logging and analyzing prompt iteration experiments with your LLM. We're going to build a simple prompt experimentation pipeline for a haiku generator. In this tutorial, you will:\n",
    "\n",
    "*   Set up an Arize dataset\n",
    "\n",
    "*   Implement a script that generates LLM outputs\n",
    "\n",
    "*   Setup a function to evaluate the output using an LLM\n",
    "\n",
    "*   Log the data in Arize to compare results across prompts\n",
    "\n",
    "‚ÑπÔ∏è This notebook requires:\n",
    "- An OpenAI API key\n",
    "- An Arize Space ID & Developer Key (explained below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrDX_J7SJMOw"
   },
   "source": [
    "# Setup Config\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko6NuWKlI39R"
   },
   "source": [
    "Copy the Arize developer API Key and Space ID from the Datasets page (shown below) to the variables in the cell below.\n",
    "\n",
    "<center><img src=\"https://storage.googleapis.com/arize-assets/fixtures/dataset_api_key.png\" width=\"700\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq \"arize[Datasets]>7.29.0\" \"arize-phoenix-evals>=0.17.5\" openai==1.57.1 datasets==3.2.0 pyarrow==18.1.0 pydantic==2.10.3 nest_asyncio==1.6.0 pandas==2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "SPACE_ID = getpass(\"üîë Enter your Arize space_id\")\n",
    "DEVELOPER_KEY = getpass(\"üîë Enter your Arize developer key\")\n",
    "API_KEY = getpass(\"üîë Enter your Arize API Key\")\n",
    "OPENAI_API_KEY = getpass(\"üîë Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUZ8i6fmGGpK"
   },
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y9ZIOxv_hq3"
   },
   "source": [
    "Below, we'll create a dataframe of points to use for your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Datasets client\n",
    "import pandas as pd\n",
    "from arize.experimental.datasets import ArizeDatasetsClient\n",
    "from arize.experimental.datasets.utils.constants import GENERATIVE\n",
    "\n",
    "arize_client = ArizeDatasetsClient(developer_key=DEVELOPER_KEY, api_key=API_KEY)\n",
    "\n",
    "# Create dataframe to upload\n",
    "data = [{\"topic\": \"Zebras\"}]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create dataset in Arize\n",
    "dataset_id = arize_client.create_dataset(\n",
    "    dataset_name=\"haiku-topics-\" + str(uuid1())[:5],\n",
    "    data=df,\n",
    "    space_id=SPACE_ID,\n",
    "    dataset_type=GENERATIVE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset from Arize\n",
    "dataset = arize_client.get_dataset(space_id=SPACE_ID, dataset_id=dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zA5inxtJMOx"
   },
   "source": [
    "Let's make sure we can run async code in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZbcNrwrFYrq"
   },
   "source": [
    "# Define Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iruPHkWI_-yi"
   },
   "source": [
    "A **task** is a callable that maps the input of a dataset example to an output by invoking a chain, query engine, or LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "def create_haiku(dataset_row) -> str:\n",
    "    topic = dataset_row.get(\"topic\")\n",
    "    openai_client = openai.OpenAI()\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Write a haiku about {topic}\"}],\n",
    "        max_tokens=20,\n",
    "    )\n",
    "    assert response.choices\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9-9NxgJKMry"
   },
   "source": [
    "# Define Evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBEodkyAAH7h"
   },
   "source": [
    "Our **evaluator** is used to grade the task outputs. The function `tone_eval` is used to determine the tone of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import (\n",
    "    OpenAIModel,\n",
    "    llm_classify,\n",
    ")\n",
    "\n",
    "from arize.experimental.datasets.experiments.evaluators.base import (\n",
    "    EvaluationResult,\n",
    ")\n",
    "\n",
    "CUSTOM_TEMPLATE = \"\"\"\n",
    "You are evaluating whether tone is positive, neutral, or negative\n",
    "\n",
    "[Message]: {output}\n",
    "\n",
    "Respond with either \"positive\", \"neutral\", or \"negative\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def tone_eval(output):\n",
    "    df_in = pd.DataFrame({\"output\": output}, index=[0])\n",
    "    eval_df = llm_classify(\n",
    "        dataframe=df_in,\n",
    "        template=CUSTOM_TEMPLATE,\n",
    "        model=OpenAIModel(model=\"gpt-4o\"),\n",
    "        rails=[\"positive\", \"neutral\", \"negative\"],\n",
    "        provide_explanation=True,\n",
    "    )\n",
    "    # return score, label, explanation\n",
    "    return EvaluationResult(\n",
    "        score=1,\n",
    "        label=eval_df[\"label\"][0],\n",
    "        explanation=eval_df[\"explanation\"][0],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3piR3vqCKVnT"
   },
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oc9iRGuaAfyg"
   },
   "source": [
    "Run the function below to run your task and evaluation across your whole dataset, and see the results of your experiment in Arize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id, experiment_dataframe = arize_client.run_experiment(\n",
    "    space_id=SPACE_ID,\n",
    "    dataset_id=dataset_id,\n",
    "    task=create_haiku,\n",
    "    evaluators=[tone_eval],\n",
    "    experiment_name=f\"haiku-example-{str(uuid1())[:5]}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment_id)\n",
    "experiment_dataframe = arize_client.get_experiment(\n",
    "    space_id=SPACE_ID, experiment_id=experiment_id\n",
    ")\n",
    "experiment_dataframe"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
