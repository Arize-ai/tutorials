{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Slack Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "# <center>Logging experiments</center>\n",
    "\n",
    "Experiments are useful tools to A/B test different prompts and models for your LLM applications. This guide shows you how to log experiment results to Arize. We'll go through the following steps:\n",
    "\n",
    "* Create a dataset\n",
    "* Log an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dependencies\n",
    "1. Install python dependencies\n",
    "2. Import dependencies\n",
    "3. Set up environment variables for your Arize Space ID, API Key, and Developer Key\n",
    "4. Set up environment variables for your OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize pandas opentelemetry-sdk opentelemetry-exporter-otlp openinference-semantic-conventions nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "from arize.experimental.datasets import ArizeDatasetsClient\n",
    "from uuid import uuid1\n",
    "from arize.experimental.datasets.experiments.types import (\n",
    "    ExperimentTaskResultColumnNames,\n",
    "    EvaluationResultColumnNames,\n",
    ")\n",
    "from arize.experimental.datasets.utils.constants import GENERATIVE\n",
    "import pandas as pd\n",
    "import os\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_ID = globals().get(\"SPACE_ID\") or getpass(\n",
    "    \"ðŸ”‘ Enter your Arize Space ID: \"\n",
    ")\n",
    "API_KEY = globals().get(\"API_KEY\") or getpass(\"ðŸ”‘ Enter your Arize API Key: \")\n",
    "DEVELOPER_KEY = globals().get(\"DEVELOPER_KEY\") or getpass(\n",
    "    \"ðŸ”‘ Enter your Developer Key: \"\n",
    ")\n",
    "OPENAI_API_KEY = globals().get(\"OPENAI_API_KEY\") or getpass(\n",
    "    \"ðŸ”‘ Enter your OpenAI API key: \"\n",
    ")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "We will be using a simple dataset with two columns: `input` and `output`.\n",
    "\n",
    "Inputs are string values that you can pass to an LLM. Outputs are the expected responses that you can use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the arize client\n",
    "arize_client = ArizeDatasetsClient(developer_key=DEVELOPER_KEY, api_key=API_KEY)\n",
    "\n",
    "dataset_df = pd.DataFrame(\n",
    "    {\"input\": [\"1+1\", \"1+2\"], \"expected_output\": [\"2\", \"3\"]}\n",
    ")\n",
    "\n",
    "dataset_name = \"experiments-log-\" + str(uuid1())\n",
    "\n",
    "dataset_id = arize_client.create_dataset(\n",
    "    space_id=SPACE_ID,\n",
    "    dataset_name=dataset_name,\n",
    "    dataset_type=GENERATIVE,\n",
    "    data=dataset_df,\n",
    ")\n",
    "dataset = arize_client.get_dataset(space_id=SPACE_ID, dataset_id=dataset_id)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log experiment\n",
    "\n",
    "We will be logging an experiment with three columns:\n",
    "\n",
    "* `example_id` is the dataset row ID, which is needed to map the results to the specific dataset row with inputs and expected outputs.\n",
    "* `result` is the output of the LLM pipeline.\n",
    "* `correctness` is the evaluation label of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column mappings for task\n",
    "task_cols = ExperimentTaskResultColumnNames(\n",
    "    example_id=\"example_id\", result=\"result\"\n",
    ")\n",
    "\n",
    "# Define column mappings for evaluator\n",
    "evaluator_cols = EvaluationResultColumnNames(\n",
    "    label=\"label\",\n",
    "    score=\"score\",\n",
    "    explanation=\"explanation_text\",\n",
    ")\n",
    "\n",
    "# Example DataFrame:\n",
    "experiment_run_df = pd.DataFrame(\n",
    "    {\n",
    "        \"result\": [\"2\", \"4\"],\n",
    "        \"label\": [\"correct\", \"incorrect\"],\n",
    "        \"score\": [1, 0],\n",
    "        \"explanation_text\": [\n",
    "            \"1+1 added is 2, which is correct\",\n",
    "            \"1+2 added is 4, which is incorrect\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "experiment_run_df[\"example_id\"] = dataset[\"id\"]\n",
    "\n",
    "# Use with ArizeDatasetsClient.log_experiment()\n",
    "arize_client.log_experiment(\n",
    "    space_id=SPACE_ID,\n",
    "    experiment_name=\"my_experiment\",\n",
    "    experiment_df=experiment_run_df,\n",
    "    task_columns=task_cols,\n",
    "    evaluator_columns={\"correctness\": evaluator_cols},\n",
    "    dataset_name=dataset_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
