{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c17a6a07-18e0-492a-8fe1-f093bc745347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Slack Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "## Arize + Mosaic AI Agent Framework: Build, deploy, trace, evaluate and monitor a production quality LangGraph agent\n",
    "\n",
    "#### Note: This notebook will only run in a Databricks workspace environment.\n",
    "This notebook is adapted from Databricks's \"[Mosaic AI Agent Framework: Author and deploy a tool-calling LangGraph agent](https://docs.databricks.com/aws/en/notebooks/source/generative-ai/langgraph-tool-calling-agent.html)\" \n",
    "\n",
    "\n",
    "In this notebook you learn to:\n",
    "- Author a tool-calling LangGraph agent wrapped with `ChatAgent` and Arize auto-instrumentation for tracing\n",
    "- This agent has the capability to generate and execute python code in a stateless sandboxed environment\n",
    "- Log and deploy the agent\n",
    "- Evaluate the agent's python code using Arize LLM as a Judge evaluation\n",
    "- Invoke the agent and view traces and evaluation results in the Arize platform\n",
    "- Set up evaluation custom metrics and view them in monitors and dashboards in Arize\n",
    "\n",
    "To learn more about authoring an agent using Mosaic AI Agent Framework, see Databricks documentation ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/author-agent) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/create-chat-model)).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Databricks account and workspace ([Sign up for free](https://docs.databricks.com/aws/en/getting-started/free-trial))\n",
    "- Arize AX account ([Sign up for free](https://app.arize.com/auth/join))\n",
    "\n",
    "- Address all `TODO`s in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eeca6dc8-d6f7-47c9-b479-29032c4241b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow databricks-langchain databricks-agents uv langgraph==0.3.4  arize-otel openinference-instrumentation-langchain\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c85a16a2-e85b-4589-8128-e4fc4779ffd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Access Arize Space and API Keys from Databricks Secrets and set them as Environment Variables\n",
    "\n",
    "Create a [Arize API key and Space ID](https://docs.arize.com/arize/reference/authentication-and-security/api-keys) for the items below.  \n",
    "Set up Arize credentials using [Databricks Secrets](https://docs.databricks.com/aws/en/security/secrets/) for secure access of keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the secure keys from secrets\n",
    "ARIZE_API_KEY = dbutils.secrets.get(scope=\"ryoung\", key=\"ARIZE_API_KEY\")\n",
    "ARIZE_SPACE_ID = dbutils.secrets.get(scope=\"ryoung\", key=\"ARIZE_SPACE_ID\")\n",
    "\n",
    "# setting as environment variables to be used by the chain\n",
    "import os\n",
    "os.environ[\"ARIZE_API_KEY\"] = ARIZE_API_KEY\n",
    "os.environ[\"ARIZE_SPACE_ID\"] = ARIZE_SPACE_ID\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25325605-7367-4140-a207-724a7210d118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Create a local configuration file to store project settings:\n",
    "\n",
    "Create a file named \"`chain_config.yaml`\" with variables below. It should reside in the same folder as the notebook. These variables will be accessed from the agent code. Replace the example values with your own values:\n",
    "\n",
    "`ARIZE_PROJECT_NAME=\"databricks-langgraph-tool-calling-agent\"` <br>\n",
    "`LLM_ENDPOINT_NAME=\"databricks-claude-3-7-sonnet\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b96664d-0f7f-473e-a621-f6389c3b71aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Define the agent in code\n",
    "Define the agent code in a single cell below. This lets you easily write the agent code to a local Python file, using the `%%writefile` magic command, for subsequent logging and deployment.\n",
    "\n",
    "#### Tracing auto-instrumentation\n",
    "Opentelemetry based auto-instrumentation for Langgraph exports traces to Arize.\n",
    "\n",
    "#### Agent tools\n",
    "This agent code adds the built-in Unity Catalog function `system.ai.python_exec` to the agent. The agent code also includes commented-out sample code for adding a vector search index to perform unstructured data retrieval.\n",
    "\n",
    "`system.ai.python_exec` - Executes Python code in a stateless sandboxed environment and returns its stdout. The runtime cannot access files or read previous executions' output. All operations must be self-contained, using only standard Python libraries. Calls to other tools are prohibited. \n",
    "\n",
    "For more examples of tools to add to your agent, see Databricks documentation ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-tool) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/agent-tool))\n",
    "\n",
    "#### Wrap the LangGraph agent using the `ChatAgent` interface\n",
    "\n",
    "For compatibility with Databricks AI features, the `LangGraphChatAgent` class implements the `ChatAgent` interface to wrap the LangGraph agent. This example uses the provided convenience APIs [`ChatAgentState`](https://mlflow.org/docs/latest/python_api/mlflow.langchain.html#mlflow.langchain.chat_agent_langgraph.ChatAgentState) and [`ChatAgentToolNode`](https://mlflow.org/docs/latest/python_api/mlflow.langchain.html#mlflow.langchain.chat_agent_langgraph.ChatAgentToolNode) for ease of use.\n",
    "\n",
    "Databricks recommends using `ChatAgent` as it simplifies authoring multi-turn conversational agents using an open source standard. See MLflow's [ChatAgent documentation](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.ChatAgent).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "from typing import Any, Generator, Optional, Sequence, Union\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    "    VectorSearchRetrieverTool,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "import os\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"openinference.instrumentation.langchain._tracer\").setLevel(logging.CRITICAL)\n",
    "\n",
    "############################################\n",
    "# Arize Tracing Setup\n",
    "############################################\n",
    "#register tracer provider to send traces to Arize\n",
    "from arize.otel import register\n",
    "\n",
    "model_config = mlflow.models.ModelConfig(development_config=\"chain_config.yaml\")\n",
    "\n",
    "tracer_provider = register(\n",
    "    space_id = os.getenv(\"ARIZE_SPACE_ID\"),\n",
    "    api_key = os.getenv(\"ARIZE_API_KEY\"),\n",
    "    project_name = model_config.get(\"ARIZE_PROJECT_NAME\"),\n",
    "    #log_to_console=True\n",
    ")\n",
    "# 1 line auto instrumentation\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "LangChainInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "# TODO: Replace with your model serving endpoint\n",
    "LLM_ENDPOINT_NAME = model_config.get(\"LLM_ENDPOINT_NAME\") \n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "# TODO: Update with your system prompt\n",
    "system_prompt = \"You are a helpful assistant. Take the user's request and where applicable, use the appropriate tool if necessary to accomplish the task. If tools are not necessary, response directly to the user's request.\"\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent, enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://docs.databricks.com/en/generative-ai/agent-framework/agent-tool.html\n",
    "###############################################################################\n",
    "tools = []\n",
    "\n",
    "# You can use UDFs in Unity Catalog as agent tools\n",
    "# Below, we add the `system.ai.python_exec` UDF, which provides\n",
    "# a python code interpreter tool to our agent\n",
    "# You can also add local LangChain python tools. See https://python.langchain.com/docs/concepts/tools\n",
    "\n",
    "# TODO: Add additional tools\n",
    "uc_tool_names = [\"system.ai.python_exec\"]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)\n",
    "\n",
    "# Use Databricks vector search indexes as tools\n",
    "# See https://docs.databricks.com/en/generative-ai/agent-framework/unstructured-retrieval-tools.html\n",
    "# for details\n",
    "\n",
    "# TODO: Add vector search indexes\n",
    "# vector_search_tools = [\n",
    "#         VectorSearchRetrieverTool(\n",
    "#         index_name=\"\",\n",
    "#         # filters=\"...\"\n",
    "#     )\n",
    "# ]\n",
    "# tools.extend(vector_search_tools)\n",
    "\n",
    "#####################\n",
    "## Define agent logic\n",
    "#####################\n",
    "\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "    system_prompt: Optional[str] = None,\n",
    ") -> CompiledGraph:\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # Define the function that determines which node to go to\n",
    "    def should_continue(state: ChatAgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If there are function calls, continue. else, end\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "            + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    def call_model(\n",
    "        state: ChatAgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"tools\",\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "        return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg}) for msg in node_data[\"messages\"]\n",
    "                )\n",
    "\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, system_prompt)\n",
    "AGENT = LangGraphChatAgent(agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f52de630-1f64-40f5-abf6-3c0404c2dac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Restart Python and reset environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the secure keys from secrets\n",
    "ARIZE_API_KEY = dbutils.secrets.get(scope=\"ryoung\", key=\"ARIZE_API_KEY\")\n",
    "ARIZE_SPACE_ID = dbutils.secrets.get(scope=\"ryoung\", key=\"ARIZE_SPACE_ID\")\n",
    "\n",
    "# setting as environment variables to be used by the chain\n",
    "import os\n",
    "os.environ[\"ARIZE_API_KEY\"] = ARIZE_API_KEY\n",
    "os.environ[\"ARIZE_SPACE_ID\"] = ARIZE_SPACE_ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7237da3f-c842-48c0-a533-d093af0c12c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code).\n",
    "\n",
    "### Enable automatic authentication for Databricks resources\n",
    "For the most common Databricks resource types, Databricks supports and recommends declaring resource dependencies for the agent upfront during logging. This enables automatic authentication passthrough when you deploy the agent. With automatic authentication passthrough, Databricks automatically provisions, rotates, and manages short-lived credentials to securely access these resource dependencies from within the agent endpoint.\n",
    "\n",
    "To enable automatic authentication, specify the dependent Databricks resources when calling `mlflow.pyfunc.log_model().`\n",
    "\n",
    "  - **TODO**: If your Unity Catalog tool queries a [vector search index](docs link) or leverages [external functions](docs link), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See docs ([AWS](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#resources)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from agent import tools, LLM_ENDPOINT_NAME\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "model_config = mlflow.models.ModelConfig(development_config=\"chain_config.yaml\")\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=model_config.get(\"LLM_ENDPOINT_NAME\"))]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        model_config=\"chain_config.yaml\",\n",
    "        extra_pip_requirements= [\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            \"arize-otel\", \"openinference.instrumentation.langchain\"\n",
    "            ],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee2348c5-c499-4d5b-8990-7899269b08b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pre-deployment agent validation\n",
    "Before registering and deploying the agent, perform pre-deployment checks using the [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API. See Databricks documentation ([AWS](https://docs.databricks.com/en/machine-learning/model-serving/model-serving-debug.html#validate-inputs) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/model-serving-debug#before-model-deployment-validation-checks))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]},\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba019ce2-7f3e-461a-b896-372805f19c00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Before you deploy the agent, you must register the agent to Unity Catalog.\n",
    "\n",
    "- **TODO** Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"prasad_kona_isv\"\n",
    "schema = \"demo\"\n",
    "model_name = \"langgraph-tool-calling-agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c571a3-dac3-4f21-a5e4-57c891702874",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "agents.deploy(\n",
    "                UC_MODEL_NAME, \n",
    "                uc_registered_model_info.version, \n",
    "                tags = {\"endpointSource\": \"docs\"},\n",
    "                scale_to_zero_enabled=True,\n",
    "                environment_vars={\n",
    "                    \"ARIZE_API_KEY\": \"{{secrets/<configration profile>/ARIZE_API_KEY}}\",\n",
    "                    \"ARIZE_SPACE_ID\": \"{{secrets/<configuration profile >/ARIZE_SPACE_ID}}\",\n",
    "                }\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ac67332-68ed-44eb-ac56-cf10ebbf29b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configure Online Evaluations in Arize AX \n",
    "\n",
    "Follow instructions [here](https://docs.arize.com/arize/evaluate/online-evals/run-evaluations-in-the-ui) to setup up online evaluations in Arize AX.\n",
    "\n",
    "Arize's Online Evaluations automatically run LLM-as-a-Judge based evaluations directly on the traces collected in the Arize platform from our Agent runs. This provides continuous quality monitoring without manual intervention. This approach scales to thousands of interactions, enabling data-driven improvements to your agent's performance.  These evaluations are for assessing code generation quality that the agent produces, specifically:\n",
    "\n",
    "- Code Correctness: Does the generated code solve the user's problem accurately?\n",
    "- Code Readability: Is the code clean, well-structured, and maintainable?\n",
    "\n",
    "References: \n",
    "- LLM-as-a-Judge evaluation best practices: ([Arize docs]((https://docs.arize.com/arize/evaluate/llm-as-a-judge))\n",
    "- Agent evaluation best practices: ([Arize Docs]((https://docs.arize.com/arize/concepts/agent-evaluation))\n",
    "- Automate running evaluations on your Traces and Spans: ([Docs]((https://docs.arize.com/arize/evaluate/online-evals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a24869c9-eaa5-4ea5-a4a8-55ed7415f3c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "![Add Image #1 here](https://storage.googleapis.com/arize-assets/tutorials/images/databricks-eval.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "745dd0f1-a354-4488-8d51-16382a351468",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Call the agent\n",
    "\n",
    "There are several methods we can use to call our newly deployed agent in Databricks.\n",
    "- REST API Calls: You can invoke your deployed agent through HTTP POST requests to the model serving endpoint. This method provides programmatic access, allowing you to integrate the agent into applications or automated workflows by sending JSON payloads with your input data and receiving structured responses.\n",
    "- Model Serving UI: Databricks provides a built-in web interface where you can directly test your deployed agent. Simply navigate to the serving endpoint in the Databricks workspace, use the \"Test\" tab to input sample data, and see real-time responses without writing any code.\n",
    "- Databricks AI Playground: This interactive environment lets you experiment with your agent in a conversational interface. You can test different prompts, observe the agent's behavior, and refine your interactions before implementing them in production scenarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example REST API Call via Curl \n",
    "\n",
    "# #1 - Basic question (no code generation)\n",
    "curl \\\n",
    "-u token:$DATABRICKS_TOKEN \\\n",
    "-X POST \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\"prompt\": \"What is a lakehouse?\", \"max_tokens\": 64}' \\\n",
    "https://<workspace_host>.databricks.com/serving-endpoints/<your-agents-serving-endpoint-name>/invocations\n",
    "\n",
    "# #2 - Math question (code generation)\n",
    "curl \\\n",
    "-u token:$DATABRICKS_TOKEN \\\n",
    "-X POST \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\"prompt\": \"What is 5*5 in python?\", \"max_tokens\": 64}' \\\n",
    "https://<workspace_host>.databricks.com/serving-endpoints/<your-agents-serving-endpoint-name>/invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example calling the agent using openai sdk\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# In a Databricks notebook you can use this:\n",
    "DATABRICKS_HOSTNAME = dbutils.notebook.entry_point.getDbutils().notebook().getContext().browserHostName().get()\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "serving_endpoint_name = \"<your-agents-serving-endpoint-name>\"\n",
    "\n",
    "client = OpenAI(\n",
    "   api_key=DATABRICKS_TOKEN,\n",
    "   base_url=f\"https://{DATABRICKS_HOSTNAME}/serving-endpoints\"\n",
    ")\n",
    "chat_completion = client.chat.completions.create(\n",
    "   messages=[\n",
    "       {\n",
    "           \"role\": \"system\",\n",
    "           \"content\": \"You are an AI assistant\"\n",
    "       },\n",
    "       {\n",
    "           \"role\": \"user\",\n",
    "           \"content\": \"Tell me about Large Language Models in one sentence\"\n",
    "       }\n",
    "   ],\n",
    "   model=serving_endpoint_name,\n",
    "   max_tokens=256\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content) if chat_completion and chat_completion.choices else print(chat_completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e389509d-d4f6-4c2e-8619-fdc1f091fb9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## View traces and evaluation results in Arize\n",
    "\n",
    "As you run your agent, traces are automatically sent to Arize. In the Arize platform, you can see agent execution details, tool invocations, latency breakdown by component, token usage and costs, errors and metadata captured for each span and function call.  Additionally, evaluation labels are captured for every trace based on the code correctness and code readability evals we setup earlier.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0d36118-897f-4f26-bb4c-03afb72f27ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "![](https://storage.googleapis.com/arize-assets/tutorials/images/databricks-trace.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ee1108f-5b45-46c3-a86e-d298d4ee84ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](https://storage.googleapis.com/arize-assets/tutorials/images/databricks-trace-screenshot.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c2a59f2-6c7e-42c9-9200-f200e94f32d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Monitoring, alerting and KPI dashboards in Arize AX\n",
    "Turn any trace attribute and evaluation label into [custom metrics](https://docs.arize.com/arize/machine-learning/machine-learning/how-to-ml/custom-metrics-api/12.-custom-metrics).  Build KPI driven [dashboards](https://docs.arize.com/arize/observe/dashboards) and [monitors](https://docs.arize.com/arize/observe/production-monitoring) that proactively alert you when any degradation in performance or quality of your agent occurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9bcade3-e495-4f2d-a7f9-1394e820d026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](https://storage.googleapis.com/arize-assets/tutorials/images/databricks-kpi-dashboard.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95b3a51c-5d2c-4233-8316-addb648d28e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](https://storage.googleapis.com/arize-assets/tutorials/images/databricks-monitor.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f368007-8e1a-45e8-a275-eafc7f4b80b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See Databricks documentation ([AWS](https://docs.databricks.com/en/generative-ai/deploy-agent.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/deploy-agent)).\n",
    "\n",
    "\n",
    "\n",
    "####Resources\n",
    "\n",
    "Databricks Resources\n",
    "- [Mosaic AI Agent Framework Documentation](https://docs.databricks.com/aws/en/data-governance/unity-catalog/)\n",
    "- [Unity Catalog Tools Guide](https://docs.databricks.com/generative-ai/agent-framework/agent-tool)\n",
    "\n",
    "Arize Resources\n",
    "- [Free Arize Sign Up](https://app.arize.com/auth/join)\n",
    "- [Agent Evaluation Best Practices](https://docs.arize.com/arize/concepts/agent-evaluation)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
