{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 4: Tools and MCP - Workshop\n",
        " \n",
        "Welcome to **Section 4**: Tools and MCP!\n",
        " \n",
        "In this section, we'll explore how to empower language model agents with external tools and a Multi-Component Pipeline (MCP) for more advanced reasoning and automation. We'll build on the backend logic from `main.py` to demonstrate how agents can interact with APIs, databases, and structured workflows.\n",
        "\n",
        "Here's what we'll cover:\n",
        "- **4.1 Planning + Reasoning (TODO list):**  \n",
        "  Learn how agents can break down complex tasks into actionable steps, plan their approach, and delegate subtasks‚Äîjust like a human would when facing a big project.\n",
        " - **4.2 APIs:**  \n",
        "   Discover how to connect your agent to external APIs, enabling it to fetch real-time data, perform actions, or integrate with other services.\n",
        " - **4.3 Querying Database (SQL):**  \n",
        "   See how agents can interact with databases using SQL, allowing them to retrieve, update, or analyze structured information as part of their workflow.\n",
        " - **4.4 MCP Structure:**  \n",
        "   Understand the architecture of a Multi-Component Pipeline (MCP), which orchestrates multiple tools and reasoning steps to solve more sophisticated problems.\n",
        " \n",
        " Throughout this lab, we'll build simple, practical examples to illustrate each concept and help you apply these techniques in your own projects!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# Load environment  \n",
        "project_root = Path.cwd()\n",
        "if project_root.name != 'agent-mastery-course':\n",
        "    project_root = project_root.parent\n",
        "load_dotenv(project_root / 'backend' / '.env')\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, SystemMessage  \n",
        "from langchain_openai import ChatOpenAI\n",
        "from openinference.instrumentation.mcp import MCPInstrumentor\n",
        "\n",
        "print(\"‚úÖ Setup complete! Ready to build tools like in main.py\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from arize.otel import register\n",
        "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
        "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
        "\n",
        "# configure the Phoenix tracer\n",
        "tracer_provider = register(\n",
        "    space_id=os.getenv(\"ARIZE_SPACE_ID\"),\n",
        "    api_key=os.getenv(\"ARIZE_API_KEY\"),\n",
        "    project_name=\"lab4-tools-and-mcp\",\n",
        ")\n",
        "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)\n",
        "LangChainInstrumentor().instrument(tracer_provider=tracer_provider, include_chains=True, include_agents=True, include_tools=True)\n",
        "MCPInstrumentor().instrument(tracer_provider=tracer_provider)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Planning + Reasoning (TODO list)\n",
        "\n",
        "Create agents that can break down complex tasks into manageable steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 - Orchestrator agent with LangGraph (plan + delegate)\n",
        "from typing import List, Dict, Any\n",
        "from typing_extensions import TypedDict, Annotated\n",
        "import operator\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.messages import SystemMessage, BaseMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Simple worker tools\n",
        "@tool\n",
        "def flights_worker(task: str) -> str:\n",
        "    \"\"\"Handle flight and visa related tasks.\"\"\"\n",
        "    return f\"Flights Agent: will handle '{task}'\"\n",
        "\n",
        "@tool\n",
        "def hotels_worker(task: str) -> str:\n",
        "    \"\"\"Handle hotel and accommodation tasks.\"\"\"\n",
        "    return f\"Hotels Agent: will handle '{task}'\"\n",
        "\n",
        "@tool\n",
        "def itinerary_worker(task: str) -> str:\n",
        "    \"\"\"Handle itinerary planning tasks.\"\"\"\n",
        "    return f\"Itinerary Agent: will handle '{task}'\"\n",
        "\n",
        "@tool\n",
        "def logistics_worker(task: str) -> str:\n",
        "    \"\"\"Handle local transport and logistics tasks.\"\"\"\n",
        "    return f\"Logistics Agent: will handle '{task}'\"\n",
        "\n",
        "class PlanState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    destination: str\n",
        "    assignments: Annotated[List[str], operator.add]\n",
        "\n",
        "def _pick_worker(task: str) -> str:\n",
        "    low = task.lower()\n",
        "    if \"flight\" in low or \"visa\" in low:\n",
        "        return flights_worker.name  # type: ignore[attr-defined]\n",
        "    if \"hotel\" in low or \"accommodation\" in low:\n",
        "        return hotels_worker.name  # type: ignore[attr-defined]\n",
        "    if \"itinerary\" in low or \"plan\" in low:\n",
        "        return itinerary_worker.name  # type: ignore[attr-defined]\n",
        "    return logistics_worker.name  # type: ignore[attr-defined]\n",
        "\n",
        "def orchestrator_node(state: PlanState) -> PlanState:\n",
        "    destination = state[\"destination\"]\n",
        "    tools = [flights_worker, hotels_worker, itinerary_worker, logistics_worker]\n",
        "    agent = llm.bind_tools(tools)\n",
        "\n",
        "    prompt = (\n",
        "        \"You are an orchestrator. Create 5 concise tasks for planning a trip to {destination}.\\n\"\n",
        "        \"For each task, immediately call exactly one tool among flights_worker, hotels_worker, itinerary_worker, logistics_worker\"\n",
        "        \" with the task string. Output only tool calls.\"\n",
        "    )\n",
        "\n",
        "    res = agent.invoke([SystemMessage(content=prompt.format(destination=destination))])\n",
        "\n",
        "    assignments: List[str] = []\n",
        "    if getattr(res, \"tool_calls\", None):\n",
        "        tool_node = ToolNode(tools)\n",
        "        tr = tool_node.invoke({\"messages\": [res]})\n",
        "        for m in tr[\"messages\"]:\n",
        "            txt = getattr(m, \"content\", \"\")\n",
        "            if txt:\n",
        "                assignments.append(txt)\n",
        "    else:\n",
        "        # Fallback: simple deterministic plan + assignment if the model doesn't emit tool calls\n",
        "        fallback_tasks = [\n",
        "            \"Book flights\",\n",
        "            \"Reserve accommodation\",\n",
        "            \"Create daily itinerary\",\n",
        "            \"Research local transport options\",\n",
        "            \"Check visa requirements\",\n",
        "        ]\n",
        "        for t in fallback_tasks: \n",
        "            w = _pick_worker(t)\n",
        "            if w == flights_worker.name:  # type: ignore[attr-defined]\n",
        "                assignments.append(flights_worker.invoke({\"task\": t}))\n",
        "            elif w == hotels_worker.name:  # type: ignore[attr-defined]\n",
        "                assignments.append(hotels_worker.invoke({\"task\": t}))\n",
        "            elif w == itinerary_worker.name:  # type: ignore[attr-defined]\n",
        "                assignments.append(itinerary_worker.invoke({\"task\": t}))\n",
        "            else:\n",
        "                assignments.append(logistics_worker.invoke({\"task\": t}))\n",
        "\n",
        "    return {\"messages\": [SystemMessage(content=\"orchestration_complete\")], \"assignments\": assignments}\n",
        "\n",
        "# Build and run the mini-graph\n",
        "G = StateGraph(PlanState)\n",
        "G.add_node(\"orchestrator\", orchestrator_node)\n",
        "G.add_edge(START, \"orchestrator\")\n",
        "G.add_edge(\"orchestrator\", END)\n",
        "planner_graph = G.compile()\n",
        "\n",
        "result = planner_graph.invoke({\"messages\": [], \"destination\": \"Tokyo\", \"assignments\": []})\n",
        "print(\"üß† Orchestrated plan + delegation (LangGraph):\")\n",
        "for line in result.get(\"assignments\", []):\n",
        "    print(\"  - \" + str(line))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Try it yourself\n",
        "\n",
        "- Run the previous cell to generate a TODO list with the LLM and see a simple delegation simulation.\n",
        "- Change the destination (e.g., \"Paris\", \"Bangkok\") to observe different TODOs.\n",
        "- Optional: extend `delegate_tasks` to include due dates or priorities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 APIs\n",
        "\n",
        "Learn how to integrate external APIs with agents (simulated based on main.py patterns).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API tools (budget_basics and attraction_prices)\n",
        "import time\n",
        "\n",
        "@tool \n",
        "def get_flight_prices(destination: str, duration: str) -> str:\n",
        "    \"\"\"Get flight prices for a destination (simulated API call).\"\"\"\n",
        "    # Simulate API latency and error handling\n",
        "    time.sleep(0.3)\n",
        "    \n",
        "    # Mock API data (like main.py's deterministic approach)\n",
        "    prices = {\n",
        "        \"Tokyo\": \"$800-1200\",\n",
        "        \"Paris\": \"$600-900\", \n",
        "        \"Bangkok\": \"$700-1000\"\n",
        "    }\n",
        "    \n",
        "    city = destination.split(\",\")[0].strip()\n",
        "    price = prices.get(city, \"$500-800\")\n",
        "    \n",
        "    return f\"‚úàÔ∏è Flight prices to {destination} ({duration}): {price} round-trip\"\n",
        "\n",
        "@tool\n",
        "def get_hotel_rates(destination: str, duration: str) -> str:\n",
        "    \"\"\"Get hotel rates for a destination (simulated API call).\"\"\"\n",
        "    # Simulate API call with error handling\n",
        "    try:\n",
        "        time.sleep(0.2)\n",
        "        \n",
        "        # Mock hotel data (like main.py's budget approach)\n",
        "        rates = {\n",
        "            \"Tokyo\": \"$100-300/night\",\n",
        "            \"Paris\": \"$80-250/night\",\n",
        "            \"Bangkok\": \"$50-150/night\" \n",
        "        }\n",
        "        \n",
        "        city = destination.split(\",\")[0].strip()\n",
        "        rate = rates.get(city, \"$75-200/night\")\n",
        "        \n",
        "        return f\"üè® Hotel rates in {destination} ({duration}): {rate}\"\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"API Error: Could not fetch hotel rates - {str(e)}\"\n",
        "\n",
        "# Test API tools\n",
        "print(\"üåê Testing API integration:\")\n",
        "print(get_flight_prices.invoke({\"destination\": \"Tokyo\", \"duration\": \"7 days\"}))\n",
        "print(get_hotel_rates.invoke({\"destination\": \"Tokyo\", \"duration\": \"7 days\"}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Querying Database (SQL)\n",
        "\n",
        "Build agents that can generate and execute SQL queries safely.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple database querying\n",
        "import sqlite3\n",
        "\n",
        "# Create a simple in-memory database\n",
        "def create_test_db():\n",
        "    conn = sqlite3.connect(':memory:')\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Create sample travel data table\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE destinations (\n",
        "            id INTEGER PRIMARY KEY,\n",
        "            city TEXT,\n",
        "            country TEXT, \n",
        "            avg_temp INTEGER,\n",
        "            best_season TEXT\n",
        "        )\n",
        "    ''')\n",
        "    \n",
        "    # Insert sample data\n",
        "    destinations = [\n",
        "        (1, 'Tokyo', 'Japan', 22, 'Spring'),\n",
        "        (2, 'Paris', 'France', 18, 'Summer'),\n",
        "        (3, 'Bangkok', 'Thailand', 30, 'Winter')\n",
        "    ]\n",
        "    \n",
        "    cursor.executemany(\n",
        "        'INSERT INTO destinations VALUES (?, ?, ?, ?, ?)', \n",
        "        destinations\n",
        "    )\n",
        "    \n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "# Initialize database\n",
        "db = create_test_db()\n",
        "\n",
        "@tool\n",
        "def query_destinations(city: str) -> str:\n",
        "    \"\"\"Query destination information from database.\"\"\"\n",
        "    # Safe SQL query (no user input directly in SQL)\n",
        "    cursor = db.cursor()\n",
        "    cursor.execute(\n",
        "        \"SELECT city, country, avg_temp, best_season FROM destinations WHERE city LIKE ?\", \n",
        "        (f\"%{city}%\",)\n",
        "    )\n",
        "    \n",
        "    result = cursor.fetchone()\n",
        "    if result:\n",
        "        city, country, temp, season = result\n",
        "        return f\"üèôÔ∏è {city}, {country}: Avg temp {temp}¬∞C, best time: {season}\"\n",
        "    else:\n",
        "        return f\"No destination data found for {city}\"\n",
        "\n",
        "@tool \n",
        "def get_all_destinations() -> str:\n",
        "    \"\"\"Get all available destinations from database.\"\"\"\n",
        "    cursor = db.cursor()\n",
        "    cursor.execute(\"SELECT city, country FROM destinations\")\n",
        "    results = cursor.fetchall()\n",
        "    \n",
        "    if results:\n",
        "        destinations = [f\"{city}, {country}\" for city, country in results]\n",
        "        return \"Available destinations: \" + \", \".join(destinations)\n",
        "    else:\n",
        "        return \"No destinations in database\"\n",
        "\n",
        "# Test database tools\n",
        "print(\"üóÑÔ∏è Testing database queries:\")\n",
        "print(get_all_destinations.invoke({}))\n",
        "print(query_destinations.invoke({\"city\": \"Tokyo\"}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.4 MCP\n",
        "\n",
        "This example spins up an in-process FastMCP server, registers a simple `weather_mcp` tool, and calls it via an MCP client ‚Äî the same pattern used in `backend/main.py`. MCP spans will be captured automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mcp.server import FastMCP\n",
        "from mcp.shared.memory import create_connected_server_and_client_session\n",
        "import asyncio\n",
        "\n",
        "# Deterministic weather data\n",
        "WEATHER_DB = {\n",
        "    \"prague\": {\"temperature\": \"6-14¬∞C\", \"conditions\": \"Crisp mornings, light rain\", \"advice\": \"Layer up and carry a compact umbrella\"},\n",
        "    \"bangkok\": {\"temperature\": \"27-33¬∞C\", \"conditions\": \"Humid afternoons, evening storms\", \"advice\": \"Light fabrics, hydrate, bring a poncho\"},\n",
        "    \"dubai\": {\"temperature\": \"24-36¬∞C\", \"conditions\": \"Dry heat with breezy nights\", \"advice\": \"High-SPF sunscreen and breathable layers\"},\n",
        "    \"barcelona\": {\"temperature\": \"14-24¬∞C\", \"conditions\": \"Sunny with a coastal breeze\", \"advice\": \"Light jacket for evenings, sunscreen by day\"},\n",
        "    \"tokyo\": {\"temperature\": \"10-22¬∞C\", \"conditions\": \"Cool mornings, clear afternoons\", \"advice\": \"Layered outfits and comfortable rainproof shoes\"},\n",
        "}\n",
        "\n",
        "def build_summary(destination: str) -> str:\n",
        "    key = destination.split(\",\")[0].strip().lower()\n",
        "    payload = WEATHER_DB.get(key)\n",
        "    if payload:\n",
        "        return (\n",
        "            f\"MCP Weather ‚Ä¢ {destination}: {payload['temperature']} with {payload['conditions']}. \"\n",
        "            f\"Tip: {payload['advice']}.\"\n",
        "        )\n",
        "    return (\n",
        "        f\"MCP Weather ‚Ä¢ {destination}: Seasonal averages unavailable. \"\n",
        "        \"Check a forecast a few days ahead and pack adaptable layers.\"\n",
        "    )\n",
        "\n",
        "# Start an in-memory server and call the tool via a client session\n",
        "server = FastMCP(name=\"Weather MCP Demo\", instructions=\"Deterministic weather tool for instrumentation demos.\")\n",
        "\n",
        "@server.tool(name=\"weather_mcp\", description=\"Return a simple weather briefing for a destination.\")\n",
        "def weather_tool(destination: str) -> str:\n",
        "    return build_summary(destination)\n",
        "\n",
        "async def run_demo():\n",
        "    async with create_connected_server_and_client_session(server._mcp_server, raise_exceptions=True) as session:\n",
        "        await session.list_tools()  # populate tool metadata\n",
        "        result = await session.call_tool(\"weather_mcp\", {\"destination\": \"Tokyo, Japan\"})\n",
        "        if result.isError:\n",
        "            raise RuntimeError(\"MCP weather tool returned an error result\")\n",
        "        parts = []\n",
        "        for block in result.content:\n",
        "            text_val = getattr(block, \"text\", None)\n",
        "            if text_val:\n",
        "                parts.append(text_val)\n",
        "        print(\"\\nüå¶Ô∏è MCP result:\")\n",
        "        print(\"\\n\".join(parts).strip())\n",
        "\n",
        "print(\"üîå MCP demo: running in-process FastMCP\")\n",
        "try:\n",
        "    # If an event loop is already running (e.g., Jupyter), use top-level await\n",
        "    loop = asyncio.get_running_loop()\n",
        "    await run_demo()\n",
        "except RuntimeError:\n",
        "    # No running loop; create one\n",
        "    asyncio.run(run_demo())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Key Takeaways:\n",
        "- **Tools make agents practical** by connecting them to real systems\n",
        "- **Safety first**: Always validate and sanitize inputs  \n",
        "- **Error handling**: Gracefully handle API failures and database errors\n",
        "- **MCP enables scalability** with distributed, observable tool architectures\n",
        "\n",
        "### Next Steps:\n",
        "1. Try building your own tools for specific use cases\n",
        "2. Explore the full main.py implementation\n",
        "3. Enable MCP and see the weather service in action\n",
        "4. Move to Section 5: RAG + Agentic RAG\n",
        "\n",
        "Great work! üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
