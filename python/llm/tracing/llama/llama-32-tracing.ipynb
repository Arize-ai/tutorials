{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "588eec5d-f95a-4a40-af8d-7923c23d39d6",
      "metadata": {
        "id": "588eec5d-f95a-4a40-af8d-7923c23d39d6"
      },
      "source": [
        "\n",
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Community</a>\n",
        "    </p>\n",
        "</center>\n",
        "\n",
        "# <center>Tracing Llama 3.2 with the OpenAI API </center>\n",
        "This guide demonstrates how to use trace open-source models like Llama 3.2, utilizing the OpenAI API.\n",
        "\n",
        "To instrument an open-source Llama model, Ollama has built-in compatibility with the OpenAI [Chat Completions API](https://github.com/ollama/ollama/blob/main/docs/openai.md), making it possible to use more tooling and applications with open-source models locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "791aaa01-f8eb-439e-85a9-4e87a83e95cb",
      "metadata": {
        "id": "791aaa01-f8eb-439e-85a9-4e87a83e95cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-instrumentation-fastapi 0.49b0 requires opentelemetry-instrumentation==0.49b0, but you have opentelemetry-instrumentation 0.49b2 which is incompatible.\n",
            "opentelemetry-instrumentation-fastapi 0.49b0 requires opentelemetry-semantic-conventions==0.49b0, but you have opentelemetry-semantic-conventions 0.49b2 which is incompatible.\n",
            "opentelemetry-instrumentation-fastapi 0.49b0 requires opentelemetry-util-http==0.49b0, but you have opentelemetry-util-http 0.49b2 which is incompatible.\n",
            "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.0 which is incompatible.\n",
            "opentelemetry-instrumentation-asgi 0.49b0 requires opentelemetry-instrumentation==0.49b0, but you have opentelemetry-instrumentation 0.49b2 which is incompatible.\n",
            "opentelemetry-instrumentation-asgi 0.49b0 requires opentelemetry-semantic-conventions==0.49b0, but you have opentelemetry-semantic-conventions 0.49b2 which is incompatible.\n",
            "opentelemetry-instrumentation-asgi 0.49b0 requires opentelemetry-util-http==0.49b0, but you have opentelemetry-util-http 0.49b2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q \"arize-otel>=0.7.0\" \"openinference-instrumentation-openai>=0.1.18\" \n",
        "\n",
        "!pip install -q colab-xterm==0.2.0 ollama==0.4.4 openai==1.57.1 opentelemetry-sdk==1.28.2 opentelemetry-exporter-otlp==1.28.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1pywoSqFyYQ0",
      "metadata": {
        "id": "1pywoSqFyYQ0"
      },
      "source": [
        "### Installing Ollama\n",
        "\n",
        "Download and execute the installation script from the Ollama website. The script will handle the installation process automatically, including downloading and installing necessary dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jd_O1lqWuXUZ",
      "metadata": {
        "id": "jd_O1lqWuXUZ"
      },
      "outputs": [],
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xl4mKLnVyF5G",
      "metadata": {
        "id": "xl4mKLnVyF5G"
      },
      "source": [
        "### Launching Xterm\n",
        "\n",
        "\n",
        "Launch the xterm terminal within the Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HhC-PUWhwBQ7",
      "metadata": {
        "id": "HhC-PUWhwBQ7"
      },
      "outputs": [],
      "source": [
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iD6_T9YtynIY",
      "metadata": {
        "id": "iD6_T9YtynIY"
      },
      "source": [
        "### Launch Terminal & Start the Ollama Server\n",
        "Once Ollama is installed and the terminal is running, we can start the server using the following command. Be sure to run this in the `xterm` terminal below!\n",
        "\n",
        "```shell\n",
        "ollama serve &\n",
        "```\n",
        "\n",
        "The `&` at the end runs the command in the background, allowing you to continue using your terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mizH98mqwCs5",
      "metadata": {
        "id": "mizH98mqwCs5"
      },
      "outputs": [],
      "source": [
        "%xterm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AN74saWz0z4c",
      "metadata": {
        "id": "AN74saWz0z4c"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe757dc-09e9-4556-8713-3cb0b3ef02b9",
      "metadata": {
        "id": "dfe757dc-09e9-4556-8713-3cb0b3ef02b9"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "import ollama\n",
        "from arize.otel import register\n",
        "from openai import OpenAI\n",
        "\n",
        "# OpenInference - Instrumentation\n",
        "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T6Ry-HLOy5vt",
      "metadata": {
        "id": "T6Ry-HLOy5vt"
      },
      "source": [
        "### Download Llama 3.2\n",
        "\n",
        "Using the `ollama` library , we can request the `llama3.2:1b` model to run in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X5OCPJv9wgnA",
      "metadata": {
        "id": "X5OCPJv9wgnA"
      },
      "outputs": [],
      "source": [
        "LLAMA_MODEL_NAME = \"llama3.2:1b\"\n",
        "\n",
        "PROJECT_NAME = f\"arize_{LLAMA_MODEL_NAME}_openai\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TpmneBW4t4Hr",
      "metadata": {
        "id": "TpmneBW4t4Hr"
      },
      "outputs": [],
      "source": [
        "ollama.pull(LLAMA_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P4ZTqUF9zF5r",
      "metadata": {
        "id": "P4ZTqUF9zF5r"
      },
      "source": [
        "### Register OTEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea7129f",
      "metadata": {
        "id": "aea7129f"
      },
      "outputs": [],
      "source": [
        "SPACE_ID = getpass(\"ðŸ”‘ Enter your Arize Space ID: \")\n",
        "API_KEY = getpass(\"ðŸ”‘ Enter your Arize API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5293e053-3547-4dbc-a456-0bda6f8432a5",
      "metadata": {
        "id": "5293e053-3547-4dbc-a456-0bda6f8432a5"
      },
      "outputs": [],
      "source": [
        "tracer_provider = register(\n",
        "    space_id=SPACE_ID,  # in app space settings page\n",
        "    api_key=API_KEY,  # in app space settings page\n",
        "    project_name=PROJECT_NAME,  # name this to whatever you would like\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15802f98-856f-4580-bda5-3f8e3e863544",
      "metadata": {
        "id": "15802f98-856f-4580-bda5-3f8e3e863544"
      },
      "outputs": [],
      "source": [
        "# Instrument OpenAI calls in your application\n",
        "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AtMyzsITzMBJ",
      "metadata": {
        "id": "AtMyzsITzMBJ"
      },
      "source": [
        "### Create OpenAI Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eceadac6-df16-45d6-949d-fcfe54618d52",
      "metadata": {
        "id": "eceadac6-df16-45d6-949d-fcfe54618d52"
      },
      "outputs": [],
      "source": [
        "oai_client = OpenAI(\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"ollama\",  # required, but unused\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7QnOYmRDzSxU",
      "metadata": {
        "id": "7QnOYmRDzSxU"
      },
      "source": [
        "### Run Queries\n",
        "\n",
        "Run queries against `llama3.2:1b`, using the OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbdd69d-95e6-4ee4-a06a-c2fe0fef746a",
      "metadata": {
        "id": "fcbdd69d-95e6-4ee4-a06a-c2fe0fef746a"
      },
      "outputs": [],
      "source": [
        "def ollama_query(oai_client: OpenAI, model_name: str, query: str):\n",
        "    response = oai_client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": query},\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "045453c0-760b-49ed-afb8-aa6d3dece7fa",
      "metadata": {
        "id": "045453c0-760b-49ed-afb8-aa6d3dece7fa"
      },
      "outputs": [],
      "source": [
        "lst_questions = [\n",
        "    \"What are Large Language Models?\",\n",
        "    \"How do large language models work?\",\n",
        "    \"How are LLMs trained, and what data is used?\",\n",
        "    \"In a large language model, what is a hallucination?\",\n",
        "    \"What are the main applications of large language models?\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48589948-cd6c-46e1-a0cb-6a524feddaef",
      "metadata": {
        "id": "48589948-cd6c-46e1-a0cb-6a524feddaef"
      },
      "outputs": [],
      "source": [
        "for question in tqdm(lst_questions):\n",
        "    llm_response = ollama_query(\n",
        "        oai_client=oai_client, model_name=LLAMA_MODEL_NAME, query=question\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
