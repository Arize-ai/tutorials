{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a",
   "metadata": {
    "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a"
   },
   "source": [
    "\n",
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "# <center>Bedrock Tracing</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36",
   "metadata": {
    "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36"
   },
   "source": [
    "This guide demonstrates how to use Arize for monitoring and debugging your LLM using Traces and Spans. You can read more about LLM tracing [here](https://docs.arize.com/arize/llm-large-language-models/llm-traces). In this tutorial, you will use opentelemetry and [openinference](https://github.com/Arize-ai/openinference/tree/main) to instrument our application in order to send traces to Arize.\n",
    "\n",
    "‚ÑπÔ∏è This notebook requires:\n",
    "- An AWS account\n",
    "- An Arize Space & API Key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f02b0-f638-4da8-a72d-371b07a5a28c",
   "metadata": {
    "id": "899f02b0-f638-4da8-a72d-371b07a5a28c"
   },
   "source": [
    "## Step 1: Install Dependencies üìö\n",
    "Let's get the notebook setup with dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398520d-47d5-450e-a0c6-3969ede28626",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openinference-instrumentation-bedrock\n",
    "!pip install opentelemetry-exporter-otlp\n",
    "!pip install arize-otel\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0c55e-69f0-4d81-b65e-13388866b467",
   "metadata": {
    "id": "7bf0c55e-69f0-4d81-b65e-13388866b467"
   },
   "source": [
    "## Step 2: Get your API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c",
   "metadata": {
    "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c"
   },
   "source": [
    "Copy the Arize `API_KEY` and `SPACE_ID` from your Space Settings page (shown below) to the variables in the cell below.\n",
    "\n",
    "Follow this guide for setting up your [AWS credentials](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html). You will need to enable model access for Bedrock [here](https://us-east-2.console.aws.amazon.com/bedrock/home#/modelaccess).\n",
    "\n",
    "<center><img src=\"https://storage.googleapis.com/arize-assets/barcelos/Screenshot%202024-11-11%20at%209.28.27%E2%80%AFPM.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3a52e-873c-4128-a183-a9db38f51305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "SPACE_ID = globals().get(\"SPACE_ID\") or getpass(\n",
    "    \"üîë Enter your Arize Space ID: \"\n",
    ")\n",
    "API_KEY = globals().get(\"API_KEY\") or getpass(\"üîë Enter your Arize API Key: \")\n",
    "\n",
    "AWS_ACCESS_KEY_ID = globals().get(\"AWS_ACCESS_KEY_ID\") or getpass(\n",
    "    \"üîë Enter your AWS Access Key ID: \"\n",
    ")\n",
    "AWS_SECRET_ACCESS_KEY = globals().get(\"AWS_SECRET_ACCESS_KEY\") or getpass(\n",
    "    \"üîë Enter your AWS Secret Access Key: \"\n",
    ")\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
    "# OPENAI_API_KEY = globals().get(\"OPENAI_API_KEY\") or getpass(\n",
    "#     \"üîë Enter your OpenAI API key: \"\n",
    "# )\n",
    "# os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2131d82c-3e83-4b0f-9845-f879af0dd641",
   "metadata": {
    "id": "2131d82c-3e83-4b0f-9845-f879af0dd641"
   },
   "source": [
    "## Step 3. Add our tracing code\n",
    "We will be using the `arize-otel` package to register the URL and authentication parameters to send to Arize using OpenTelemetry. You can see what's under the hood by looking [here](https://docs.arize.com/arize/large-language-models/tracing/auto-instrumentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e103c2-5b87-4ba3-9d8d-c250a748ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import open-telemetry dependencies\n",
    "from arize.otel import register\n",
    "\n",
    "# Setup OTEL via our convenience function\n",
    "tracer_provider = register(\n",
    "    space_id=SPACE_ID,\n",
    "    api_key=API_KEY,\n",
    "    project_name=\"tracing-haiku-tutorial\",\n",
    ")\n",
    "# Import the automatic instrumentor from OpenInference\n",
    "from openinference.instrumentation.bedrock import BedrockInstrumentor\n",
    "\n",
    "# Start the instrumentor for Bedrock\n",
    "BedrockInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59",
   "metadata": {
    "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59"
   },
   "source": [
    "## Step 4: Run your LLM application\n",
    "Let's test our app by asking to write a haiku. If you have difficulty invoking the model, you can change the modelId to the ARN of a model that you have access to ([see guide here](https://repost.aws/questions/QUEU82wbYVQk2oU4eNwyiong/bedrock-api-invocation-error-on-demand-throughput-isn-s-supported)).\n",
    "\n",
    "The invocation parameters are also different for Bedrock vs. traditional LLM inference. Here's the Bedrock docs for [invoke_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime.html#BedrockRuntime.Client.invoke_model) vs. [converse](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/converse.html#converse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13d61d-3cab-4e07-a14b-357038646ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    ")\n",
    "client = session.client(\"bedrock-runtime\", region_name=\"us-east-2\")\n",
    "model_id = \"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"text\": \"Hello, how are you?\"}]}]\n",
    "\n",
    "response = client.converse(\n",
    "    messages=messages,\n",
    "    modelId=model_id,\n",
    ")\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(response.get(\"output\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d327bfe",
   "metadata": {},
   "source": [
    "This also works with `invoke_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc933ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = b'{\"prompt\": \"Human: Hello there, how are you? Assistant:\"}'\n",
    "response = client.invoke_model(modelId=model_id, body=prompt)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "print(response_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a4000-8267-44a1-a849-768167aa6624",
   "metadata": {
    "id": "e20a4000-8267-44a1-a849-768167aa6624"
   },
   "source": [
    "Here's an example with boto3 agents. You will need to set up an agent in the AWS console, make sure it's deployed, and then create an alias for it. Make sure the region_name is correct or else the agent will not work.\n",
    "\n",
    "Example URL to access the console: https://us-east-2.console.aws.amazon.com/bedrock/home?region=us-east-2#agents\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/amazon-bedrock-agents.png\" width=\"700\">\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/amazon-bedrock-agents-setup.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a89d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=\"us-east-2\")\n",
    "timestamp = int(time.time())\n",
    "response = runtime_client.invoke_agent(\n",
    "    agentId=\"\",\n",
    "    agentAliasId=\"\",\n",
    "    inputText=\"write me a haiku about a cat\",\n",
    "    sessionId=f\"default-session1-{timestamp}\",\n",
    "    enableTrace=True,\n",
    ")\n",
    "completion = \"\"\n",
    "for event in response.get(\"completion\"):\n",
    "    if \"chunk\" in event:\n",
    "        completion += event[\"chunk\"][\"bytes\"].decode()\n",
    "    elif \"trace\" in event:\n",
    "        print(event[\"trace\"])\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6",
   "metadata": {
    "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6"
   },
   "source": [
    "## Step 5: Log into Arize and explore your application traces üöÄ\n",
    "\n",
    "Log into your Arize account, and look for the project with the same `project_name`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
