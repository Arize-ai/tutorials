{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a",
   "metadata": {
    "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a"
   },
   "source": [
    "\n",
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "# <center>Tracing with Mistral</center>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36",
   "metadata": {
    "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36"
   },
   "source": [
    "This guide demonstrates how to use Arize for monitoring and debugging your LLM using Traces and Spans. You can read more about LLM tracing [here](https://docs.arize.com/arize/llm-large-language-models/llm-traces). In this tutorial, you will use opentelemetry and [openinference](https://github.com/Arize-ai/openinference/tree/main) to instrument our application in order to send traces to Arize.\n",
    "\n",
    "â„¹ï¸ This notebook requires:\n",
    "- A Mistral API key\n",
    "- An Arize Space & API Key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f02b0-f638-4da8-a72d-371b07a5a28c",
   "metadata": {
    "id": "899f02b0-f638-4da8-a72d-371b07a5a28c"
   },
   "source": [
    "## Step 1: Install Dependencies ðŸ“š\n",
    "Let's get the notebook setup with dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2398520d-47d5-450e-a0c6-3969ede28626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Dependencies needed to instrument your openai application using opentelemetry and openinference\n",
    "!pip3 install -q arize-otel openinference-instrumentation-mistralai opentelemetry-sdk opentelemetry-exporter-otlp opentelemetry-instrumentation-httpx mistralai 'httpx<0.28'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0c55e-69f0-4d81-b65e-13388866b467",
   "metadata": {
    "id": "7bf0c55e-69f0-4d81-b65e-13388866b467"
   },
   "source": [
    "## Step 2: Get your API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c",
   "metadata": {
    "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c"
   },
   "source": [
    "Copy the Arize API_KEY and SPACE_ID from your Space Settings page (shown below) to the variables in the cell below.\n",
    "\n",
    "<center><img src=\"https://storage.googleapis.com/arize-assets/barcelos/Screenshot%202024-11-11%20at%209.28.27%E2%80%AFPM.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f3a52e-873c-4128-a183-a9db38f51305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not (SPACE_ID := os.getenv(\"SPACE_ID\")):\n",
    "    SPACE_ID = getpass(\"ðŸ”‘ Enter your Space ID: \")\n",
    "\n",
    "if not (API_KEY := os.getenv(\"API_KEY\")):\n",
    "    API_KEY = getpass(\"ðŸ”‘ Enter your API Key: \")\n",
    "\n",
    "if not (MISTRAL_API_KEY := os.getenv(\"MISTRAL_API_KEY\")):\n",
    "    MISTRAL_API_KEY = getpass(\"ðŸ”‘ Enter your Mistral API key: \")\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2131d82c-3e83-4b0f-9845-f879af0dd641",
   "metadata": {
    "id": "2131d82c-3e83-4b0f-9845-f879af0dd641"
   },
   "source": [
    "## Step 3. Add our tracing code\n",
    "We will be using the arize_otel package to register the URL and authentication parameters to send to Arize using OpenTelemetry. You can see what's under the hood by looking [here](https://docs.arize.com/arize/large-language-models/tracing/auto-instrumentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e103c2-5b87-4ba3-9d8d-c250a748ff31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "# Import open-telemetry dependencies\n",
    "from arize_otel import register_otel, Endpoints\n",
    "\n",
    "# Setup OTEL via our convenience function\n",
    "register_otel(\n",
    "    endpoints=Endpoints.ARIZE,\n",
    "    space_id=SPACE_ID,  # in app space settings page\n",
    "    api_key=API_KEY,  # in app space settings page\n",
    "    project_name=\"mistral-tracing-tutorial\",  # name this to whatever you would like\n",
    ")\n",
    "# Import the automatic instrumentor from OpenInference\n",
    "from openinference.instrumentation.mistralai import MistralAIInstrumentor\n",
    "\n",
    "# Finish automatic instrumentation\n",
    "MistralAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59",
   "metadata": {
    "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59"
   },
   "source": [
    "## Step 4: Run your LLM application\n",
    "Let's test our app by asking Mistral to write a haiku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e13d61d-3cab-4e07-a14b-357038646ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='75482209a868449ea46ed5df53ca6e2e' object='chat.completion' model='mistral-small-latest' usage=UsageInfo(prompt_tokens=8, completion_tokens=20, total_tokens=28) created=1733421290 choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content=\"Sure, here's a haiku for you:\\n\\nWhispers of the breeze,\", tool_calls=None, prefix=False, role='assistant'), finish_reason='length')]\n"
     ]
    }
   ],
   "source": [
    "from mistralai import Mistral\n",
    "\n",
    "# Run Mistral completion\n",
    "mistral_client = Mistral(api_key=MISTRAL_API_KEY)\n",
    "response = mistral_client.chat.complete(\n",
    "    model=\"mistral-small-latest\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a haiku.\"}],\n",
    "    max_tokens=20,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a4000-8267-44a1-a849-768167aa6624",
   "metadata": {
    "id": "e20a4000-8267-44a1-a849-768167aa6624"
   },
   "source": [
    "Great! Our application works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6",
   "metadata": {
    "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6"
   },
   "source": [
    "## Step 5: Log into Arize and explore your application traces ðŸš€\n",
    "\n",
    "Log into your Arize account, and look for the project with the same `project_name`.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/tutorials/images/arize-llm-tracing.png\" width=\"1500\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
