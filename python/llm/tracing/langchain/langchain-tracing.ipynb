{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Awn1jcNa0lLZ"
   },
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "<center><h1>Using Arize with Langchain ü¶úüîó </h1></center>\n",
    "\n",
    "LangChain is a framework that helps you prototype LLM applications quickly. Use Arize and LangChain together to trace, evaluate, and iterate on your LLM apps and agents.\n",
    "\n",
    "### Running This Notebook\n",
    "1. Step through each section below, pressing play on the code blocks to run the cells.\n",
    "2. Log in your browser to the Arize App\n",
    "3. Copy and paste your Arize Space ID and API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X9GuXoSXleA"
   },
   "source": [
    "# Step 0. Install Dependencies\n",
    "\n",
    "Install Langchain and Arize packages.\n",
    "\n",
    "‚ö†Ô∏è Use a GPU to save time generating embeddings. Click on 'Runtime', select 'Change Runtime Type' and\n",
    "select 'GPU'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q langchain langchain_community langchain-openai 'httpx<0.28'\n",
    "!pip3 install -q arize arize-otel openinference-instrumentation-langchain \n",
    "!pip3 install -q 'arize[AutoEmbeddings]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMjE6vwOOKS-"
   },
   "source": [
    "# Step 1. Setup Tracing\n",
    "\n",
    "Copy the Arize `API_KEY` and `SPACE_ID` from your Space Settings page (shown below) to the variables in the cell below.\n",
    "\n",
    "<center><img src=\"https://storage.googleapis.com/arize-assets/barcelos/Screenshot%202024-11-11%20at%209.28.27%E2%80%AFPM.png\" width=\"700\"></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import open-telemetry dependencies\n",
    "from arize.otel import register\n",
    "from getpass import getpass\n",
    "\n",
    "# Setup OTEL via our convenience function\n",
    "tracer_provider = register(\n",
    "    space_id=getpass(\"Enter your Arize Space ID:\"),\n",
    "    api_key=getpass(\"Enter your Arize API Key:\"),\n",
    "    project_name=\"langchain-tracing\",\n",
    ")\n",
    "\n",
    "# Import the automatic instrumentor from OpenInference\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "# Finish automatic instrumentation\n",
    "LangChainInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jjWMK3wo_FX"
   },
   "source": [
    "## Step 2: Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec97f_LONfp3"
   },
   "source": [
    "## Step 3: Test LLM Responses and Logging into Arize\n",
    "Use some simple prompts to test if the LLM works properly and each prompt-response pair is logged into Arize with embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = llm.generate(\n",
    "    [\n",
    "        \"Tell me an interesting fact about pandas.\",\n",
    "        \"Explain the concept of overfitting in 2 sentences.\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DGWWhYOflGZ"
   },
   "source": [
    "## Step 4: Test LLM Chain and Agents with Arize Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
    "Title: {title}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
    "Play Synopsis:\n",
    "{synopsis}\n",
    "Review from a New York Times play critic of the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"synopsis\"], template=template\n",
    ")\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[synopsis_chain, review_chain], verbose=True\n",
    ")\n",
    "\n",
    "test_prompts = [\n",
    "    {\n",
    "        \"input\": \"documentary about pandas who are about be extinct because of global warming\"\n",
    "    },\n",
    "    {\"input\": \"once upon a time in hollywood\"},\n",
    "    {\"input\": \"the best mo observability tooling\"},\n",
    "]\n",
    "overall_chain.apply(test_prompts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
