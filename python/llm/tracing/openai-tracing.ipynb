{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a",
      "metadata": {
        "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a"
      },
      "source": [
        "\n",
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
        "    </p>\n",
        "</center>\n",
        "\n",
        "# <center>Getting Started with Tracing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36",
      "metadata": {
        "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36"
      },
      "source": [
        "This guide demonstrates how to use Arize for monitoring and debugging your LLM using Traces and Spans. You can read more about LLM tracing [here](https://docs.arize.com/arize/llm-large-language-models/llm-traces). In this tutorial, you will use opentelemetry and [openinference](https://github.com/Arize-ai/openinference/tree/main) to instrument our application in order to send traces to Arize.\n",
        "\n",
        "ℹ️ This notebook requires:\n",
        "- An OpenAI API key\n",
        "- An Arize Space & API Key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899f02b0-f638-4da8-a72d-371b07a5a28c",
      "metadata": {
        "id": "899f02b0-f638-4da8-a72d-371b07a5a28c"
      },
      "source": [
        "## Step 1: Install Dependencies 📚\n",
        "Let's get the notebook setup with dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2398520d-47d5-450e-a0c6-3969ede28626",
      "metadata": {
        "id": "2398520d-47d5-450e-a0c6-3969ede28626",
        "outputId": "587b7259-63fc-4e95-89e0-533c8a06be24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arize-otel\n",
            "  Downloading arize_otel-0.5.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.3)\n",
            "Collecting openinference-instrumentation-openai\n",
            "  Downloading openinference_instrumentation_openai-0.1.17-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.10/dist-packages (1.28.0)\n",
            "Collecting opentelemetry-exporter-otlp\n",
            "  Downloading opentelemetry_exporter_otlp-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting openinference-semantic-conventions>=0.1.5 (from arize-otel)\n",
            "  Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting opentelemetry-proto>=1.12.0 (from arize-otel)\n",
            "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting openinference-instrumentation>=0.1.18 (from openinference-instrumentation-openai)\n",
            "  Downloading openinference_instrumentation-0.1.18-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-openai) (1.28.0)\n",
            "Collecting opentelemetry-instrumentation (from openinference-instrumentation-openai)\n",
            "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-openai) (0.49b0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-openai) (1.16.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api->openinference-instrumentation-openai) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api->openinference-instrumentation-openai) (8.5.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.28.1 (from opentelemetry-exporter-otlp)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.28.1 (from opentelemetry-exporter-otlp)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.1->opentelemetry-exporter-otlp) (1.65.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.1->opentelemetry-exporter-otlp) (1.67.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc==1.28.1->opentelemetry-exporter-otlp)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-sdk\n",
            "  Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: requests~=2.7 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http==1.28.1->opentelemetry-exporter-otlp) (2.32.3)\n",
            "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto>=1.12.0->arize-otel)\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-otlp\n",
            "  Downloading opentelemetry_exporter_otlp-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.28.0 (from opentelemetry-exporter-otlp)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.28.0 (from opentelemetry-exporter-otlp)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc==1.28.0->opentelemetry-exporter-otlp)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto>=1.12.0 (from arize-otel)\n",
            "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-instrumentation to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-instrumentation (from openinference-instrumentation-openai)\n",
            "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation->openinference-instrumentation-openai) (24.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api->openinference-instrumentation-openai) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.28.1->opentelemetry-exporter-otlp) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.28.1->opentelemetry-exporter-otlp) (2.2.3)\n",
            "Downloading arize_otel-0.5.3-py3-none-any.whl (9.2 kB)\n",
            "Downloading openinference_instrumentation_openai-0.1.17-py3-none-any.whl (23 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.28.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.28.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.28.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl (18 kB)\n",
            "Downloading openinference_instrumentation-0.1.18-py3-none-any.whl (14 kB)\n",
            "Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl (9.1 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl (30 kB)\n",
            "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, openinference-semantic-conventions, opentelemetry-proto, opentelemetry-exporter-otlp-proto-common, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openinference-instrumentation, opentelemetry-exporter-otlp, openinference-instrumentation-openai, arize-otel\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arize-otel-0.5.3 openinference-instrumentation-0.1.18 openinference-instrumentation-openai-0.1.17 openinference-semantic-conventions-0.1.12 opentelemetry-exporter-otlp-1.28.0 opentelemetry-exporter-otlp-proto-common-1.28.0 opentelemetry-exporter-otlp-proto-grpc-1.28.0 opentelemetry-exporter-otlp-proto-http-1.28.0 opentelemetry-instrumentation-0.49b0 opentelemetry-proto-1.28.0 protobuf-5.28.3\n"
          ]
        }
      ],
      "source": [
        "# Dependencies needed to instrument your openai application using opentelemetry and openinference\n",
        "!pip install arize-otel openai openinference-instrumentation-openai opentelemetry-sdk opentelemetry-exporter-otlp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bf0c55e-69f0-4d81-b65e-13388866b467",
      "metadata": {
        "id": "7bf0c55e-69f0-4d81-b65e-13388866b467"
      },
      "source": [
        "## Step 2: Get your API Keys"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c",
      "metadata": {
        "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c"
      },
      "source": [
        "Copy the Arize API_KEY and SPACE_ID from your Space Settings page (shown below) to the variables in the cell below.\n",
        "\n",
        "<center><img src=\"https://storage.googleapis.com/arize-assets/barcelos/Screenshot%202024-11-11%20at%209.28.27%E2%80%AFPM.png\" width=\"700\"></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f3a52e-873c-4128-a183-a9db38f51305",
      "metadata": {
        "id": "83f3a52e-873c-4128-a183-a9db38f51305",
        "outputId": "4c97c7d8-85b8-4b48-f99b-3e49c38d9183",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Import and Setup Arize Client Done! Now we can start using Arize!\n"
          ]
        }
      ],
      "source": [
        "SPACE_ID = \"SPACE_ID\" # Change this line\n",
        "API_KEY = \"API_KEY\" # Change this line\n",
        "\n",
        "if SPACE_ID == \"SPACE_ID\" or API_KEY == \"API_KEY\":\n",
        "    raise ValueError(\"❌ NEED TO CHANGE SPACE AND/OR API_KEY\")\n",
        "else:\n",
        "    print(\"✅ Import and Setup Arize Client Done! Now we can start using Arize!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add your OpenAI key below to test OpenAI instrumentation"
      ],
      "metadata": {
        "id": "jRdvmgJOVTdM"
      },
      "id": "jRdvmgJOVTdM"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
        "    openai_api_key = getpass(\"🔑 Enter your OpenAI API key: \")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "GC0Njs7_VP7o",
        "outputId": "fe1a63cf-c362-42a5-b11e-13d75e9fa1d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GC0Njs7_VP7o",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔑 Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2131d82c-3e83-4b0f-9845-f879af0dd641",
      "metadata": {
        "id": "2131d82c-3e83-4b0f-9845-f879af0dd641"
      },
      "source": [
        "## Step 3. Add our tracing code\n",
        "We will be using the arize_otel package to register the URL and authentication parameters to send to Arize using OpenTelemetry. You can see what's under the hood by looking [here](https://docs.arize.com/arize/large-language-models/tracing/auto-instrumentation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e103c2-5b87-4ba3-9d8d-c250a748ff31",
      "metadata": {
        "id": "d1e103c2-5b87-4ba3-9d8d-c250a748ff31"
      },
      "outputs": [],
      "source": [
        "# Import open-telemetry dependencies\n",
        "from arize_otel import register_otel, Endpoints\n",
        "\n",
        "# Setup OTEL via our convenience function\n",
        "register_otel(\n",
        "    endpoints = Endpoints.ARIZE,\n",
        "    space_id = SPACE_ID, # in app space settings page\n",
        "    api_key = API_KEY, # in app space settings page\n",
        "    model_id = \"tracing-haiku-tutorial\", # name this to whatever you would like\n",
        ")\n",
        "# Import the automatic instrumentor from OpenInference\n",
        "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
        "\n",
        "# Finish automatic instrumentation\n",
        "OpenAIInstrumentor().instrument()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59",
      "metadata": {
        "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59"
      },
      "source": [
        "## Step 4: Run your LLM application\n",
        "Let's test our app by asking OpenAI to write a haiku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e13d61d-3cab-4e07-a14b-357038646ad2",
      "metadata": {
        "id": "4e13d61d-3cab-4e07-a14b-357038646ad2",
        "outputId": "50e94dc5-2a1a-48bc-ff54-a46269edbdb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whispering wind blows\n",
            "Through the branches of tall trees\n",
            "Nature's symphony.\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# Run OpenAI completion\n",
        "openai_client = openai.OpenAI()\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Write a haiku.\"}],\n",
        "    max_tokens=20,\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e20a4000-8267-44a1-a849-768167aa6624",
      "metadata": {
        "id": "e20a4000-8267-44a1-a849-768167aa6624"
      },
      "source": [
        "Great! Our application works!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6",
      "metadata": {
        "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6"
      },
      "source": [
        "## Step 5: Log into Arize and explore your application traces 🚀\n",
        "\n",
        "Log into your Arize account, and look for the model with the same `model_id`.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/arize-assets/tutorials/images/arize-llm-tracing.png\" width=\"1500\" />"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}