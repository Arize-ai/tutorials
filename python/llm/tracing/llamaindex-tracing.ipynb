{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a",
      "metadata": {
        "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a"
      },
      "source": [
        "\n",
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
        "    </p>\n",
        "</center>\n",
        "\n",
        "# <center>LlamaIndex Tracing using Arize</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36",
      "metadata": {
        "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36"
      },
      "source": [
        "This guide demonstrates how to use Arize for monitoring and debugging your LLM using Traces and Spans. We're going to build a simple query engine using LlamaIndex and retrieval-augmented generation (RAG) to answer questions about the [Arize documentation](https://docs.arize.com/arize/). You can read more about LLM tracing [here](https://docs.arize.com/arize/llm-large-language-models/llm-traces). Arize makes your LLM applications observable by visualizing the underlying structure of each call to your query engine and surfacing problematic `spans` of execution based on latency, token count, or other evaluation metrics.\n",
        "\n",
        "In this tutorial, you will:\n",
        "1. Use opentelemetry and [openinference](https://github.com/Arize-ai/openinference/tree/main) to instrument our application in order to send traces to Arize.\n",
        "2. Build a simple query engine using LlamaIndex that uses RAG to answer questions about the Arize documentation\n",
        "3. Inspect the traces and spans of your application to identify sources of latency and cost\n",
        "\n",
        "癸 This notebook requires:\n",
        "- An OpenAI API key\n",
        "- An Arize Space & API Key (explained below)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899f02b0-f638-4da8-a72d-371b07a5a28c",
      "metadata": {
        "id": "899f02b0-f638-4da8-a72d-371b07a5a28c"
      },
      "source": [
        "## Step 1: Install Dependencies \n",
        "Let's get the notebook setup with dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2398520d-47d5-450e-a0c6-3969ede28626",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2398520d-47d5-450e-a0c6-3969ede28626",
        "outputId": "29a0b7ff-1d61-4596-fade-0b599cd341b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: openinference-instrumentation-llama-index in /usr/local/lib/python3.10/dist-packages (3.0.4)\n",
            "Collecting arize-otel\n",
            "  Downloading arize_otel-0.5.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (3.11.2)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: fsspec==2024.10.0 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2024.10.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.32.3)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.12.1)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.6.2)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48.post4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.2)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openinference-instrumentation>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index) (0.1.18)\n",
            "Requirement already satisfied: openinference-semantic-conventions>=0.1.9 in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index) (0.1.12)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index) (0.49b2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index) (4.12.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp>=1.22 in /usr/local/lib/python3.10/dist-packages (from arize-otel) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-proto>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from arize-otel) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22 in /usr/local/lib/python3.10/dist-packages (from arize-otel) (1.28.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.54.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.1->llama-index) (2.0.36)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (11.0.0)\n",
            "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (4.66.6)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.1->llama-index) (0.9.0)\n",
            "Requirement already satisfied: llama-cloud>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp>=1.22->arize-otel) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp>=1.22->arize-otel) (1.28.2)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp>=1.22->arize-otel) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp>=1.22->arize-otel) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp>=1.22->arize-otel) (1.28.2)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto>=1.12.0->arize-otel) (5.28.3)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api->openinference-instrumentation-llama-index) (8.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (2024.8.30)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.7.2)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation->openinference-instrumentation-llama-index) (24.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.25.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->gcsfs) (1.6.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api->openinference-instrumentation-llama-index) (3.21.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.1->llama-index) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.1->llama-index) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.1->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.1->llama-index) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.1->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.1->llama-index) (2.23.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.1->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.1->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.1->llama-index) (3.23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.1->llama-index) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
            "Downloading arize_otel-0.5.3-py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: arize-otel\n",
            "Successfully installed arize-otel-0.5.3\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp in /usr/local/lib/python3.10/dist-packages (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp) (1.28.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (1.2.15)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-api~=1.15 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-proto==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-sdk~=1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (1.28.2)\n",
            "Requirement already satisfied: requests~=2.7 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http==1.28.2->opentelemetry-exporter-otlp) (2.32.3)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.28.2->opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (5.28.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (1.16.0)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk~=1.28.2->opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (0.49b2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk~=1.28.2->opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.28.2->opentelemetry-exporter-otlp) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.28.2->opentelemetry-exporter-otlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.28.2->opentelemetry-exporter-otlp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.28.2->opentelemetry-exporter-otlp) (2024.8.30)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-grpc==1.28.2->opentelemetry-exporter-otlp) (3.21.0)\n"
          ]
        }
      ],
      "source": [
        "# Dependencies needed to build the Llama Index RAG application\n",
        "!pip install gcsfs llama-index openinference-instrumentation-llama-index arize-otel\n",
        "\n",
        "# Dependencies needed to export spans and send them to our collectors: Arize\n",
        "!pip install opentelemetry-exporter-otlp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bf0c55e-69f0-4d81-b65e-13388866b467",
      "metadata": {
        "id": "7bf0c55e-69f0-4d81-b65e-13388866b467"
      },
      "source": [
        "## Step 2: Tracing your application"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c",
      "metadata": {
        "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c"
      },
      "source": [
        "Copy the Arize API_KEY and SPACE_ID from your Space Settings page (shown below) to the variables in the cell below.\n",
        "\n",
        "<center><img src=\"https://storage.googleapis.com/arize-assets/barcelos/Screenshot%202024-11-11%20at%209.28.27%E2%80%AFPM.png\" width=\"700\"></center>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import open-telemetry dependencies\n",
        "from arize_otel import register_otel, Endpoints\n",
        "from getpass import getpass\n",
        "\n",
        "# Setup OTEL via our convenience function\n",
        "register_otel(\n",
        "    endpoints = Endpoints.ARIZE,\n",
        "    space_id = getpass(\"Enter your Arize Space ID:\"),\n",
        "    api_key = getpass(\"Enter your Arize API Key:\"),\n",
        "    model_id = \"llamaindex-tracing\",\n",
        ")\n",
        "\n",
        "# Import the automatic instrumentor from OpenInference\n",
        "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "\n",
        "# Finish automatic instrumentation\n",
        "LlamaIndexInstrumentor().instrument(skip_dep_check=True)"
      ],
      "metadata": {
        "id": "81rxKGBABwe8",
        "outputId": "0772c403-ba03-4227-efcf-5d83b2e39313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "81rxKGBABwe8",
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Arize Space ID:路路路路路路路路路路\n",
            "Enter your Arize API Key:路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59",
      "metadata": {
        "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59"
      },
      "source": [
        "## Step 3: Build Your Llama Index RAG Application \n",
        "Let's import the dependencies we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a0731faa-f263-4441-9cee-50460b5842a0",
      "metadata": {
        "id": "a0731faa-f263-4441-9cee-50460b5842a0"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "from gcsfs import GCSFileSystem\n",
        "from llama_index.core import (\n",
        "    Settings,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8874e8d7-2a95-4547-8061-768e9acab805",
      "metadata": {
        "id": "8874e8d7-2a95-4547-8061-768e9acab805"
      },
      "source": [
        "Set your OpenAI API key if it is not already set as an environment variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9f29abbe-5bab-49b3-a643-c15a5d4f6265",
      "metadata": {
        "id": "9f29abbe-5bab-49b3-a643-c15a5d4f6265",
        "outputId": "5842dcb7-0d39-4b17-e5d8-93025e2de6a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Enter your OpenAI API key: 路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
        "    openai_api_key = getpass(\" Enter your OpenAI API key: \")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b2fbe94-f071-47f5-9ebb-3563560814ab",
      "metadata": {
        "id": "8b2fbe94-f071-47f5-9ebb-3563560814ab"
      },
      "source": [
        "This example uses a `RetrieverQueryEngine` over a pre-built index of the Arize documentation, but you can use whatever LlamaIndex application you like. Download the pre-built index of the Arize docs from cloud storage and instantiate your storage context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "de04f2a9-cb92-4c7f-945f-0a629bdcbe20",
      "metadata": {
        "id": "de04f2a9-cb92-4c7f-945f-0a629bdcbe20",
        "outputId": "f3c334fc-6187-4e15-a922-de4394c80c21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.core.graph_stores.simple:No existing llama_index.core.graph_stores.simple found at arize-phoenix-assets/datasets/unstructured/llm/llama-index/arize-docs/index/graph_store.json. Initializing a new graph_store from scratch. \n"
          ]
        }
      ],
      "source": [
        "file_system = GCSFileSystem(project=\"public-assets-275721\")\n",
        "index_path = \"arize-phoenix-assets/datasets/unstructured/llm/llama-index/arize-docs/index/\"\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    fs=file_system,\n",
        "    persist_dir=index_path,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "806ebe03-abbc-4545-95b7-4a7a5942cba2",
      "metadata": {
        "id": "806ebe03-abbc-4545-95b7-4a7a5942cba2"
      },
      "source": [
        "We are now ready to instantiate our query engine that will perform retrieval-augmented generation (RAG). Query engine is a generic interface in LlamaIndex that allows you to ask question over your data. A query engine takes in a natural language query, and returns a rich response. It is built on top of Retrievers. You can compose multiple query engines to achieve more advanced capability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bcf35c57-8399-4d31-8e57-735e0de2ce57",
      "metadata": {
        "id": "bcf35c57-8399-4d31-8e57-735e0de2ce57"
      },
      "outputs": [],
      "source": [
        "Settings.llm = OpenAI(model=\"gpt-4o\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
        "index = load_index_from_storage(\n",
        "    storage_context,\n",
        ")\n",
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00f99cc-f3e7-4b74-a613-6c0b1df70ef1",
      "metadata": {
        "id": "e00f99cc-f3e7-4b74-a613-6c0b1df70ef1"
      },
      "source": [
        "Let's test our app by asking a question about the Arize documentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4e13d61d-3cab-4e07-a14b-357038646ad2",
      "metadata": {
        "id": "4e13d61d-3cab-4e07-a14b-357038646ad2",
        "outputId": "754d43fe-b5d3-4dff-ecc9-27c2d86591d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arize is a machine learning observability platform designed to assist AI Engineers and other ML practitioners in monitoring, troubleshooting, and explaining their models. It provides tools to monitor real-time model performance, even when there is a delay in receiving ground truth or feedback. Arize helps identify the root causes of model failures or performance degradation through tracing and explainability features. It also allows for multi-model performance comparisons and offers insights into drift, data quality, and model fairness or bias metrics. The platform is open and can integrate with existing machine learning infrastructure, available as both a SaaS and on-premise solution.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"What is Arize and how can it help me as an AI Engineer?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e20a4000-8267-44a1-a849-768167aa6624",
      "metadata": {
        "id": "e20a4000-8267-44a1-a849-768167aa6624"
      },
      "source": [
        "Great! Our application works!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd4cadb-55b5-49b1-8bf3-8e4ef7a1a4f6",
      "metadata": {
        "id": "2fd4cadb-55b5-49b1-8bf3-8e4ef7a1a4f6"
      },
      "source": [
        "## Step 4: Use our instrumented query engine\n",
        "\n",
        "We will download a dataset of queries for our RAG application to answer and see the traces appear in Arize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2096825c-ba77-4c44-9460-7b82a3de7ea7",
      "metadata": {
        "id": "2096825c-ba77-4c44-9460-7b82a3de7ea7",
        "outputId": "96df2560-e86a-4c31-c3a2-ab2a2b4fbb9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['How do I use the SDK to upload a ranking model?',\n",
              " 'What drift metrics are supported in Arize?',\n",
              " 'Does Arize support batch models?',\n",
              " 'Does Arize support training data?',\n",
              " 'How do I configure a threshold if my data has seasonality trends?']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from urllib.request import urlopen\n",
        "import json\n",
        "\n",
        "queries_url = \"http://storage.googleapis.com/arize-phoenix-assets/datasets/unstructured/llm/context-retrieval/arize_docs_queries.jsonl\"\n",
        "queries = []\n",
        "with urlopen(queries_url) as response:\n",
        "    for line in response:\n",
        "        line = line.decode(\"utf-8\").strip()\n",
        "        data = json.loads(line)\n",
        "        queries.append(data[\"query\"])\n",
        "\n",
        "queries[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "59677acb-788e-402d-ac5d-1f96b911d83c",
      "metadata": {
        "id": "59677acb-788e-402d-ac5d-1f96b911d83c",
        "outputId": "d731f181-79e0-4b2c-ed44-c5a79e06320a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 5/5 [00:10<00:00,  2.12s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from openinference.instrumentation import using_attributes\n",
        "\n",
        "N1 = 5 # Number of traces for your first session\n",
        "SESSION_ID_1 = \"session-id-1\" # Identifer for your first session\n",
        "USER_ID_1 = \"john_smith\" # Identifer for your first session\n",
        "METADATA = {\n",
        "    \"key_bool\": True,\n",
        "    \"key_str\": \"value1\",\n",
        "    \"key_int\": 1\n",
        "}\n",
        "\n",
        "qa_pairs = []\n",
        "for query in tqdm(queries[:N1]):\n",
        "    with using_attributes(\n",
        "        session_id=SESSION_ID_1,\n",
        "        user_id=USER_ID_1,\n",
        "        metadata=METADATA,\n",
        "    ):\n",
        "        resp = query_engine.query(query)\n",
        "        qa_pairs.append((query,resp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a094c7f5-3e3a-4cb1-9684-06b0e8d82c38",
      "metadata": {
        "id": "a094c7f5-3e3a-4cb1-9684-06b0e8d82c38",
        "outputId": "2731cc6b-f23a-437f-f7fb-cbbe1453d358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 3/3 [00:05<00:00,  1.68s/it]\n"
          ]
        }
      ],
      "source": [
        "N2 = 3 # Number of traces for your second session\n",
        "SESSION_ID_2 = \"session-id-2\" # Identifer for your second session\n",
        "USER_ID_2 = \"jane_doe\" # Identifer for your second session\n",
        "\n",
        "for query in tqdm(queries[N1:N1+N2]):\n",
        "    with using_attributes(\n",
        "        session_id=SESSION_ID_2,\n",
        "        user_id=USER_ID_2,\n",
        "        metadata=METADATA\n",
        "    ):\n",
        "        resp = query_engine.query(query)\n",
        "        qa_pairs.append((query,resp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "18e79697-36d1-4929-9413-05de9903d159",
      "metadata": {
        "id": "18e79697-36d1-4929-9413-05de9903d159",
        "outputId": "0955c339-5b0f-4db3-fc23-c77771810e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            ">> QUESTION: How do I use the SDK to upload a ranking model?\n",
            ">> ANSWER: The context does not provide specific instructions on using an SDK to upload a ranking model. It focuses on the challenges, use cases, and evaluation metrics for ranking models. For guidance on using an SDK to upload a ranking model, you would need to refer to the documentation or support resources specific to the SDK you are using.\n",
            "\n",
            "-------------------------------------------------------\n",
            ">> QUESTION: What drift metrics are supported in Arize?\n",
            ">> ANSWER: Arize supports drift metrics such as Population Stability Index, KL Divergence, and Wasserstein Distance.\n",
            "\n",
            "---------------------------------------------\n",
            ">> QUESTION: Does Arize support batch models?\n",
            ">> ANSWER: Yes, Arize supports many model types, which would include batch models.\n",
            "\n",
            "----------------------------------------------\n",
            ">> QUESTION: Does Arize support training data?\n",
            ">> ANSWER: Arize is focused on monitoring, troubleshooting, and explaining machine learning models rather than directly supporting training data. It provides tools for observing model performance, identifying issues, and analyzing metrics, but it does not specifically mention support for training data.\n",
            "\n",
            "------------------------------------------------------------------------------\n",
            ">> QUESTION: How do I configure a threshold if my data has seasonality trends?\n",
            ">> ANSWER: To configure a threshold for data with seasonality trends, you can use automatic thresholds that adjust dynamically based on your data. These thresholds are calculated using a statistical analysis of data over a 14-day period. You can modify the sensitivity of these thresholds by adjusting the standard deviation in the 'Monitor Settings' card. This allows the threshold to account for variations in your data, including seasonal trends.\n",
            "\n",
            "--------------------------------------------------------------------------------------\n",
            ">> QUESTION: How are clusters in the UMAP calculated? When are the clusters refreshed?\n",
            ">> ANSWER: Clusters in UMAP are calculated based on the similarity of data points, where points that are closer together in the visualization are more similar to each other. This allows for the identification of groups of related points, known as clusters, within the data. Clusters are refreshed when you select a point on the drift visualization and generate a new UMAP, which updates the visualization to reflect the selected point in time.\n",
            "\n",
            "------------------------------------------\n",
            ">> QUESTION: How does Arize calculate AUC?\n",
            ">> ANSWER: The context does not provide specific information on how Arize calculates AUC (Area Under the Curve).\n",
            "\n",
            "---------------------------------------------------------\n",
            ">> QUESTION: Can I send truth labels to Arize separtely? \n",
            ">> ANSWER: The context information does not provide details about sending truth labels separately to Arize. It would be best to contact Arize support directly for specific inquiries regarding sending truth labels.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for q,a in qa_pairs:\n",
        "    q_msg = f\">> QUESTION: {q}\"\n",
        "    print(f\"{'-'*len(q_msg)}\")\n",
        "    print(q_msg)\n",
        "    print(f\">> ANSWER: {a}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6",
      "metadata": {
        "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6"
      },
      "source": [
        "## Step 5: Log into Arize and explore your application traces \n",
        "\n",
        "Log into your Arize account, and look for the model with the same `model_id`. You are likely to see the following page if you are sending a brand new model. Arize is processing your data and your model will be accessible for you to explore your traces in no time.\n",
        "\n",
        "<center><img src=\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/model-loading-tutorial-otlp-llama-index.png\" width=\"700\"></center>\n",
        "\n",
        "After the timer is completed, you are ready to navigate and explore your traces\n",
        "\n",
        "<center><img src=\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/llm-tracing-overview-llama-index.png\" width=\"700\"></center>\n",
        "\n",
        "<center><img src=\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/llm-tracing-detail-llama-index.png\" width=\"700\"></center>\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}