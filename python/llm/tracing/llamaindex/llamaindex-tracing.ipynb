{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a",
   "metadata": {
    "id": "43f8e85c-70c2-4de3-99b8-acdbb58d6c4a"
   },
   "source": [
    "\n",
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "# <center>LlamaIndex Tracing using Arize</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36",
   "metadata": {
    "id": "94f4db8b-dc93-4cef-ac58-205d1ec21b36"
   },
   "source": [
    "This guide demonstrates how to use Arize for monitoring and debugging your LLM using Traces and Spans. We're going to build a simple query engine using LlamaIndex and retrieval-augmented generation (RAG) to answer questions about the [Arize documentation](https://docs.arize.com/arize/). You can read more about LLM tracing [here](https://docs.arize.com/arize/llm-large-language-models/llm-traces). Arize makes your LLM applications observable by visualizing the underlying structure of each call to your query engine and surfacing problematic `spans` of execution based on latency, token count, or other evaluation metrics.\n",
    "\n",
    "In this tutorial, you will:\n",
    "1. Use opentelemetry and [openinference](https://github.com/Arize-ai/openinference/tree/main) to instrument our application in order to send traces to Arize.\n",
    "2. Build a simple query engine using LlamaIndex that uses RAG to answer questions about the Arize documentation\n",
    "3. Inspect the traces and spans of your application to identify sources of latency and cost\n",
    "\n",
    "â„¹ï¸ This notebook requires:\n",
    "- An OpenAI API key\n",
    "- An Arize Space & API Key (explained below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f02b0-f638-4da8-a72d-371b07a5a28c",
   "metadata": {
    "id": "899f02b0-f638-4da8-a72d-371b07a5a28c"
   },
   "source": [
    "## Step 1: Install Dependencies ðŸ“š\n",
    "Let's get the notebook setup with dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398520d-47d5-450e-a0c6-3969ede28626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External dependencies needed to build the Llama Index RAG application and export spans to Arize\n",
    "!pip install -q gcsfs==2024.10.0 llama-index==0.12.5 opentelemetry-exporter-otlp==1.28.0\n",
    "\n",
    "# Arize dependencies needed to instrument your LlamaIndex application using opentelemetry and openinference\n",
    "!pip install -q \"openinference-instrumentation-llama-index>=3.0.4\" \"arize-otel>=0.7.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0c55e-69f0-4d81-b65e-13388866b467",
   "metadata": {
    "id": "7bf0c55e-69f0-4d81-b65e-13388866b467"
   },
   "source": [
    "## Step 2: Tracing your application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c",
   "metadata": {
    "id": "16bce764-0d42-4e9a-a86e-bee64a30a07c"
   },
   "source": [
    "Copy the Arize API_KEY and SPACE_ID from your Space Settings page (shown below) to the variables in the cell below.\n",
    "\n",
    "<center><img src=\"https://storage.googleapis.com/arize-assets/barcelos/Screenshot%202024-11-11%20at%209.28.27%E2%80%AFPM.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81rxKGBABwe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import open-telemetry dependencies\n",
    "from arize.otel import register\n",
    "from getpass import getpass\n",
    "\n",
    "# Setup OTEL via our convenience function\n",
    "tracer_provider = register(\n",
    "    space_id=getpass(\"Enter your Arize Space ID:\"),\n",
    "    api_key=getpass(\"Enter your Arize API Key:\"),\n",
    "    project_name=\"llamaindex-tracing\",\n",
    ")\n",
    "\n",
    "# Import the automatic instrumentor from OpenInference\n",
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "\n",
    "# Finish automatic instrumentation\n",
    "LlamaIndexInstrumentor().instrument(\n",
    "    tracer_provider=tracer_provider, skip_dep_check=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59",
   "metadata": {
    "id": "5b4aa150-82f5-4268-b7fd-95b059b03d59"
   },
   "source": [
    "## Step 3: Build Your Llama Index RAG Application ðŸ“\n",
    "Let's import the dependencies we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0731faa-f263-4441-9cee-50460b5842a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "from gcsfs import GCSFileSystem\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874e8d7-2a95-4547-8061-768e9acab805",
   "metadata": {
    "id": "8874e8d7-2a95-4547-8061-768e9acab805"
   },
   "source": [
    "Set your OpenAI API key if it is not already set as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29abbe-5bab-49b3-a643-c15a5d4f6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"ðŸ”‘ Enter your OpenAI API key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fbe94-f071-47f5-9ebb-3563560814ab",
   "metadata": {
    "id": "8b2fbe94-f071-47f5-9ebb-3563560814ab"
   },
   "source": [
    "This example uses a `RetrieverQueryEngine` over a pre-built index of the Arize documentation, but you can use whatever LlamaIndex application you like. Download the pre-built index of the Arize docs from cloud storage and instantiate your storage context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04f2a9-cb92-4c7f-945f-0a629bdcbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_system = GCSFileSystem(project=\"public-assets-275721\")\n",
    "index_path = \"arize-phoenix-assets/datasets/unstructured/llm/llama-index/arize-docs/index/\"\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    fs=file_system,\n",
    "    persist_dir=index_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ebe03-abbc-4545-95b7-4a7a5942cba2",
   "metadata": {
    "id": "806ebe03-abbc-4545-95b7-4a7a5942cba2"
   },
   "source": [
    "We are now ready to instantiate our query engine that will perform retrieval-augmented generation (RAG). Query engine is a generic interface in LlamaIndex that allows you to ask question over your data. A query engine takes in a natural language query, and returns a rich response. It is built on top of Retrievers. You can compose multiple query engines to achieve more advanced capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf35c57-8399-4d31-8e57-735e0de2ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-4o\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "index = load_index_from_storage(\n",
    "    storage_context,\n",
    ")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f99cc-f3e7-4b74-a613-6c0b1df70ef1",
   "metadata": {
    "id": "e00f99cc-f3e7-4b74-a613-6c0b1df70ef1"
   },
   "source": [
    "Let's test our app by asking a question about the Arize documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13d61d-3cab-4e07-a14b-357038646ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is Arize and how can it help me as an AI Engineer?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a4000-8267-44a1-a849-768167aa6624",
   "metadata": {
    "id": "e20a4000-8267-44a1-a849-768167aa6624"
   },
   "source": [
    "Great! Our application works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4cadb-55b5-49b1-8bf3-8e4ef7a1a4f6",
   "metadata": {
    "id": "2fd4cadb-55b5-49b1-8bf3-8e4ef7a1a4f6"
   },
   "source": [
    "## Step 4: Use our instrumented query engine\n",
    "\n",
    "We will download a dataset of queries for our RAG application to answer and see the traces appear in Arize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096825c-ba77-4c44-9460-7b82a3de7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "queries_url = \"http://storage.googleapis.com/arize-phoenix-assets/datasets/unstructured/llm/context-retrieval/arize_docs_queries.jsonl\"\n",
    "queries = []\n",
    "with urlopen(queries_url) as response:\n",
    "    for line in response:\n",
    "        line = line.decode(\"utf-8\").strip()\n",
    "        data = json.loads(line)\n",
    "        queries.append(data[\"query\"])\n",
    "\n",
    "queries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59677acb-788e-402d-ac5d-1f96b911d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from openinference.instrumentation import using_attributes\n",
    "\n",
    "N1 = 5  # Number of traces for your first session\n",
    "SESSION_ID_1 = \"session-id-1\"  # Identifer for your first session\n",
    "USER_ID_1 = \"john_smith\"  # Identifer for your first session\n",
    "METADATA = {\"key_bool\": True, \"key_str\": \"value1\", \"key_int\": 1}\n",
    "\n",
    "qa_pairs = []\n",
    "for query in tqdm(queries[:N1]):\n",
    "    with using_attributes(\n",
    "        session_id=SESSION_ID_1,\n",
    "        user_id=USER_ID_1,\n",
    "        metadata=METADATA,\n",
    "    ):\n",
    "        resp = query_engine.query(query)\n",
    "        qa_pairs.append((query, resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094c7f5-3e3a-4cb1-9684-06b0e8d82c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "N2 = 3  # Number of traces for your second session\n",
    "SESSION_ID_2 = \"session-id-2\"  # Identifer for your second session\n",
    "USER_ID_2 = \"jane_doe\"  # Identifer for your second session\n",
    "\n",
    "for query in tqdm(queries[N1 : N1 + N2]):\n",
    "    with using_attributes(\n",
    "        session_id=SESSION_ID_2, user_id=USER_ID_2, metadata=METADATA\n",
    "    ):\n",
    "        resp = query_engine.query(query)\n",
    "        qa_pairs.append((query, resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e79697-36d1-4929-9413-05de9903d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q, a in qa_pairs:\n",
    "    q_msg = f\">> QUESTION: {q}\"\n",
    "    print(f\"{'-'*len(q_msg)}\")\n",
    "    print(q_msg)\n",
    "    print(f\">> ANSWER: {a}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6",
   "metadata": {
    "id": "9c0fd7e0-9eae-431d-b23a-5fb8c03779b6"
   },
   "source": [
    "## Step 5: Log into Arize and explore your application traces ðŸš€\n",
    "\n",
    "Log into your Arize account, and look for the model with the same `model_id`. You are likely to see the following page if you are sending a brand new model. Arize is processing your data and your model will be accessible for you to explore your traces in no time.\n",
    "\n",
    "<center><img src=\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/model-loading-tutorial-otlp-llama-index.png\" width=\"700\"></center>\n",
    "\n",
    "After the timer is completed, you are ready to navigate and explore your traces\n",
    "\n",
    "<center><img src=\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/llm-tracing-overview-llama-index.png\" width=\"700\"></center>\n",
    "\n",
    "<center><img src=\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/llm-tracing-detail-llama-index.png\" width=\"700\"></center>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
