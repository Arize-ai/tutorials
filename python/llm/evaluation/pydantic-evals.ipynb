{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Slack Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "# <center>Evaluation using Pydantic Evals</center>\n",
    "\n",
    "1. Use Pydantic Evals to evaluate your LLM app for a simple question-answering task.\n",
    "2. Log your results to Arize to track your experiments and traces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "857d8bf104ed"
   },
   "source": [
    "## Step 1: Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pydantic-evals \"arize[Tracing]\" arize-otel openai openinference-instrumentation-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup API keys and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic_evals import Case, Dataset\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "SPACE_ID = globals().get(\"SPACE_ID\") or getpass(\n",
    "    \"ðŸ”‘ Enter your Arize Space ID: \"\n",
    ")\n",
    "API_KEY = globals().get(\"API_KEY\") or getpass(\"ðŸ”‘ Enter your Arize API Key: \")\n",
    "OPENAI_API_KEY = globals().get(\"OPENAI_API_KEY\") or getpass(\n",
    "    \"ðŸ”‘ Enter your OpenAI API key: \"\n",
    ")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Setup Arize\n",
    "Add our auto-instrumentation for OpenAI using arize-otel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ OpenTelemetry Tracing Details ðŸ”­\n",
      "|  Arize Project: pydantic-evals-tutorial\n",
      "|  Span Processor: BatchSpanProcessor\n",
      "|  Collector Endpoint: otlp.arize.com\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'space_id': '****', 'api_key': '****', 'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from arize.otel import register\n",
    "tracer_provider = register(\n",
    "    space_id=SPACE_ID,  \n",
    "    api_key=API_KEY,\n",
    "    project_name=\"pydantic-evals-tutorial\",  \n",
    ")\n",
    "\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define the Evaluation Dataset\n",
    "Create a dataset of test cases using Pydantic Evals for a question-answering task.\n",
    "1. Each Case represents a single test with an input (question) and an expected output (answer).\n",
    "2. The Dataset aggregates these cases for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [\n",
    "    Case(name=\"capital of France\", inputs=\"What is the capital of France?\", expected_output=\"Paris\"),\n",
    "    Case(name=\"author of Romeo and Juliet\", inputs=\"Who wrote Romeo and Juliet?\", expected_output=\"William Shakespeare\"),\n",
    "    Case(name=\"largest planet\", inputs=\"What is the largest planet in our solar system?\", expected_output=\"Jupiter\")\n",
    "]\n",
    "dataset = Dataset(cases=cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Setup LLM task to evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def evaluate_case(case):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": case.inputs}]\n",
    "    )\n",
    "    output = response.choices[0].message.content\n",
    "    print(output)\n",
    "    is_correct = case.expected_output.lower() in output.strip().lower()\n",
    "    return is_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run your experiment and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "\"Romeo and Juliet\" was written by William Shakespeare. It is a tragic play that tells the story of two young lovers from feuding families in Verona, Italy.\n",
      "The largest planet in our solar system is Jupiter. It is known for its immense size, strong magnetic field, and prominent features, such as the Great Red Spot, which is a massive storm. Jupiter is a gas giant and has a diameter of approximately 86,881 miles (139,822 kilometers).\n",
      "Case: capital of France, Correct: True\n",
      "Case: author of Romeo and Juliet, Correct: True\n",
      "Case: largest planet, Correct: True\n"
     ]
    }
   ],
   "source": [
    "results = [evaluate_case(case) for case in dataset.cases]\n",
    "\n",
    "for case, result in zip(dataset.cases, results):\n",
    "    print(f\"Case: {case.name}, Correct: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7. See your results in Arize\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/pydantic-evals.png\" width=\"800\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
