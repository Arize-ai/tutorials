{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "    <img alt=\"arize logo\" src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"300\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/arize/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/client_python\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-11t1vbu4x-xkBIHmOREQnYnYDH1GDfCg\">Slack Community</a>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3t0aAnodpJFU"
   },
   "source": [
    "# Session-Level Evaluations\n",
    "\n",
    "This notebook demonstrates how to evaluate the effectiveness of AI agent interactions at the session level, where a session consists of multiple traces (individual interactions) between a user and the system.\n",
    "\n",
    "## Conceptual Overview\n",
    "\n",
    "Session-level evaluations assess:\n",
    "- Coherence across multiple interactions\n",
    "- Context retention between interactions\n",
    "- Overall goal achievement across an entire conversation\n",
    "- Appropriate progression through complex multi-step tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX3Pm3NupJFV"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Configure your environment variables and import dependencies. You'll need to set up your Arize API key and import necessary libraries for data processing and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install arize arize-phoenix pandas openai nest_asyncio getpass arize-phoenix-evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import (\n",
    "    llm_classify,\n",
    "    OpenAIModel # see https://docs.arize.com/phoenix/evaluation/evaluation-models\n",
    "    # for a full list of supported models\n",
    ")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from arize.exporter import ArizeExportClient\n",
    "from arize.utils.types import Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass('Enter your Arize API key: ')\n",
    "os.environ['ARIZE_API_KEY'] = api_key\n",
    "\n",
    "space_id = getpass('Enter your Arize Space ID: ')\n",
    "os.environ['ARIZE_SPACE_ID'] = space_id\n",
    "\n",
    "model_id = getpass('Enter your Arize Space ID(Project Name): ')\n",
    "os.environ['ARIZE_MODEL_ID'] = model_id\n",
    "\n",
    "openai_key = getpass('Enter your OpenAI API key: ')\n",
    "os.environ['OPENAI_API_KEY'] = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKNbB3lNpJFW"
   },
   "source": [
    "   ## Data Extraction\n",
    "   \n",
    "   Pull trace data from Arize and prepare it for analysis.\n",
    "   \n",
    "   > **Note**: Modify the space_id, model_id, and date range to match your deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ArizeExportClient(api_key=os.environ['ARIZE_API_KEY'])\n",
    "\n",
    "print('#### Exporting your primary dataset into a dataframe.')\n",
    "\n",
    "primary_df = client.export_model_to_df(\n",
    "    space_id=os.environ['ARIZE_SPACE_ID'],\n",
    "    model_id=os.environ['ARIZE_MODEL_ID'],\n",
    "    environment=Environments.TRACING,\n",
    "    start_time=datetime.now() - timedelta(days=7),\n",
    "    end_time=datetime.now(),\n",
    "    # Optionally specify columns to improve query performance\n",
    "    # columns=['context.span_id', 'attributes.llm.input']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWiSzyCHpJFX"
   },
   "source": [
    "## Evaluation Prompt Design\n",
    "\n",
    "The evaluation uses a carefully designed prompt template that instructs the LLM how to evaluate session-level effectiveness and coherence. You can customize this template to fit your specific evaluation criteria.\n",
    "\n",
    "The session evaluation prompt focuses on:\n",
    "\n",
    "- Coherence assessment: Does the agent maintain a consistent understanding across interactions?\n",
    "- Context utilization: Does the agent effectively use information from previous interactions?\n",
    "- Goal progression: Does the conversation move logically toward resolving the user's needs?\n",
    "- Response appropriateness: Are the agent's responses suitable given the conversation history?\n",
    "\n",
    "The evaluation looks at overall conversation quality and effectiveness throughout the session.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RousiUE5pJFY"
   },
   "source": [
    "### Prompt Variables\n",
    "\n",
    "| Variable | Description | Source |\n",
    "|----------|-------------|--------|\n",
    "| `{session_user_inputs}` | The user inputs across all traces in the session | Extracted from trace data |\n",
    "| `{session_output_messages}` | The AI's responses across all traces in the session | Extracted from trace data |\n",
    "\n",
    "### Customizing the Prompt\n",
    "\n",
    "You may want to adjust the evaluation criteria or output format based on your specific use case:\n",
    "\n",
    "- Add domain-specific criteria relevant to your agent's purpose\n",
    "- Modify success criteria based on your application's goals\n",
    "- Include additional session metadata as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the session level evaluation prompt\n",
    "SESSION_CORRECTNESS_PROMPT = \"\"\"\n",
    "You are a helpful AI bot that evaluates the effectiveness and correctness of an AI agent's session.\n",
    "\n",
    "A session consists of multiple traces (interactions) between a user and an AI system. I will provide you with:\n",
    "1. The user inputs that initiated each trace in the session, in chronological order\n",
    "2. The AI's output messages for each trace in the session, in chronological order\n",
    "3. The total number of traces in this session\n",
    "\n",
    "An effective and correct session:\n",
    "- Shows consistent understanding of user intentions across traces\n",
    "- Maintains context and coherence between interactions\n",
    "- Successfully achieves the overall user goals\n",
    "- Builds upon previous interactions in the conversation\n",
    "- Avoids unnecessary repetition or confusion\n",
    "\n",
    "##\n",
    "\n",
    "User Inputs:\n",
    "{user_inputs}\n",
    "\n",
    "Output Messages:\n",
    "{output_messages}\n",
    "\n",
    "##\n",
    "\n",
    "Evaluate the session based on the given criteria:\n",
    "- Assess whether the agent maintains coherence throughout the session\n",
    "- Analyze if the session progresses logically toward resolving user requests\n",
    "- Check if the agent effectively uses context from previous interactions\n",
    "\n",
    "Your response must be a single string, either `correct` or `incorrect`, and must not include any additional text.\n",
    "\n",
    "- Respond with `correct` if the session effectively accomplishes user goals with appropriate responses and coherence.\n",
    "- Respond with `incorrect` if the session shows confusion, inappropriate responses, or fails to accomplish user goals.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1yUeuyqpJFY"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "These functions filter and transform session data into the format needed for evaluation.\n",
    "\n",
    "**Core concepts:**\n",
    "- **Session identification**: Finding complete user sessions to evaluate\n",
    "- **Trace ordering**: Arranging traces chronologically within sessions\n",
    "- **Message extraction**: Gathering user inputs and system responses across the session\n",
    "\n",
    "The `filter_sessions_by_trace_criteria` function is particularly important as it allows you to:\n",
    "1. Select relevant sessions that contain traces matching your criteria\n",
    "2. Retrieve the complete session context for evaluation\n",
    "\n",
    "This approach ensures we evaluate the full conversation flow rather than isolated interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "def filter_sessions_by_trace_criteria(\n",
    "    df: pd.DataFrame,\n",
    "    trace_filters: Dict[str, Dict[str, Any]] = {},\n",
    "    span_filters: Dict[str, Dict[str, Any]] = {},\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Filter to find sessions that contain traces meeting the specified criteria.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with trace data\n",
    "        trace_filters: Dictionary of column names and filtering criteria for traces\n",
    "                      Format: {\"column_name\": {\"operator\": value}}\n",
    "                      Supported operators: \">=\", \"<=\", \"==\", \"!=\", \"contains\", \"notna\", \"isna\"\n",
    "        span_filters: Dictionary of column names and filtering criteria for spans\n",
    "                     Format: {\"column_name\": {\"operator\": value}}\n",
    "                     Same supported operators as trace_filters\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with all spans from sessions that contain at least one matching trace\n",
    "    \"\"\"\n",
    "    # Make a copy of the dataframe\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Apply trace-level filters\n",
    "    filtered_df = df_copy.copy()\n",
    "    for column, criteria in trace_filters.items():\n",
    "        if column not in filtered_df.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in dataframe\")\n",
    "            continue\n",
    "\n",
    "        for operator, value in criteria.items():\n",
    "            filtered_df = _apply_filter(filtered_df, column, operator, value)\n",
    "\n",
    "    # Apply span-level filters\n",
    "    for column, criteria in span_filters.items():\n",
    "        if column not in filtered_df.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in dataframe\")\n",
    "            continue\n",
    "\n",
    "        for operator, value in criteria.items():\n",
    "            filtered_df = _apply_filter(filtered_df, column, operator, value)\n",
    "\n",
    "    # Get the session IDs that contain matching traces\n",
    "    if \"attributes.session.id\" not in filtered_df.columns:\n",
    "        print(\"Warning: 'attributes.session.id' column not found in dataframe\")\n",
    "        return filtered_df\n",
    "\n",
    "    matching_session_ids = set(filtered_df[\"attributes.session.id\"].unique())\n",
    "    print(\n",
    "        f\"Found {len(matching_session_ids)} sessions containing traces that match criteria\"\n",
    "    )\n",
    "\n",
    "    if not matching_session_ids:\n",
    "        print(\"No matching sessions found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Return ALL spans from matching sessions (not just the filtered ones)\n",
    "    # This ensures we have complete sessions for evaluation\n",
    "    result_df = df[df[\"attributes.session.id\"].isin(matching_session_ids)].copy()\n",
    "\n",
    "    # Get counts for reporting\n",
    "    session_count = len(matching_session_ids)\n",
    "    trace_count = len(result_df[\"context.trace_id\"].unique())\n",
    "    span_count = len(result_df)\n",
    "\n",
    "    print(\n",
    "        f\"Final result: {span_count} spans from {trace_count} traces in {session_count} sessions\"\n",
    "    )\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def _apply_filter(df, column, operator, value):\n",
    "    \"\"\"Helper function to apply a single filter operation\"\"\"\n",
    "    if operator == \">=\":\n",
    "        return df[df[column] >= value]\n",
    "    elif operator == \"<=\":\n",
    "        return df[df[column] <= value]\n",
    "    elif operator == \"==\":\n",
    "        # Special handling for None/null comparison\n",
    "        if value is None:\n",
    "            return df[df[column].isnull()]\n",
    "        else:\n",
    "            return df[df[column] == value]\n",
    "    elif operator == \"!=\":\n",
    "        # Special handling for None/null comparison\n",
    "        if value is None:\n",
    "            return df[~df[column].isnull()]\n",
    "        else:\n",
    "            return df[df[column] != value]\n",
    "    elif operator == \"contains\":\n",
    "        return df[df[column].str.contains(value, case=False, na=False)]\n",
    "    elif operator == \"isna\":\n",
    "        return df[df[column].isna()]\n",
    "    elif operator == \"notna\":\n",
    "        return df[df[column].notna()]\n",
    "    else:\n",
    "        print(f\"Warning: Unsupported operator '{operator}' - skipping\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_session_data_for_evaluation(\n",
    "    df,\n",
    "    extract_cols={\n",
    "        \"output_messages\": \"attributes.llm.output_messages\",\n",
    "        \"user_input\": \"attributes.input.value\",\n",
    "    },\n",
    "    filter_empty=True,\n",
    "    max_chars_per_value=5000,  # Maximum characters per individual value\n",
    "    max_chars_per_session=100000,  # Maximum characters per entire session\n",
    "    truncation_strategy=\"end\",  # \"start\", \"end\", or \"middle\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepare session data for evaluation by grouping by session_id and organizing trace data chronologically.\n",
    "    Includes truncation to avoid context limits.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing trace data\n",
    "        extract_cols: Dict mapping {output_key: source_column} to extract from each row\n",
    "        filter_empty: Whether to filter out empty values (default: True)\n",
    "        max_chars_per_value: Maximum characters per individual text value\n",
    "        max_chars_per_session: Maximum characters for entire session data\n",
    "        truncation_strategy: How to truncate (\"start\", \"end\", or \"middle\")\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with processed session data ready for evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    def truncate_text(text, max_chars, strategy=\"end\"):\n",
    "        \"\"\"Truncate text based on strategy\"\"\"\n",
    "        if not text or len(text) <= max_chars:\n",
    "            return text\n",
    "\n",
    "        if strategy == \"start\":\n",
    "            return \"...\" + text[-(max_chars-3):]\n",
    "        elif strategy == \"middle\":\n",
    "            half = (max_chars - 3) // 2\n",
    "            return text[:half] + \"...\" + text[-half:]\n",
    "        else:  # \"end\"\n",
    "            return text[:max_chars-3] + \"...\"\n",
    "\n",
    "    def estimate_session_size(session_dict):\n",
    "        \"\"\"Estimate total character count for a session\"\"\"\n",
    "        total_chars = 0\n",
    "        for key, value in session_dict.items():\n",
    "            if isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, dict):\n",
    "                        for sub_item in item.values():\n",
    "                            if isinstance(sub_item, list):\n",
    "                                for text in sub_item:\n",
    "                                    if isinstance(text, str):\n",
    "                                        total_chars += len(text)\n",
    "                            elif isinstance(sub_item, str):\n",
    "                                total_chars += len(sub_item)\n",
    "            elif isinstance(value, str):\n",
    "                total_chars += len(value)\n",
    "        return total_chars\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required_cols = [\"attributes.session.id\", \"context.trace_id\", \"start_time\"]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Error: Required column '{col}' not found in dataframe\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    # Group by session_id\n",
    "    session_groups = df.groupby(\"attributes.session.id\")\n",
    "\n",
    "    # Prepare results list\n",
    "    results = []\n",
    "\n",
    "    for session_id, session_data in session_groups:\n",
    "        # Initialize a dict to store session data\n",
    "        session_dict = {\"attributes.session.id\": session_id}\n",
    "\n",
    "        # Count traces in this session\n",
    "        trace_ids = session_data[\"context.trace_id\"].unique()\n",
    "        session_dict[\"trace_count\"] = len(trace_ids)\n",
    "\n",
    "        # Order traces chronologically based on the start_time of their first span\n",
    "        trace_start_times = {}\n",
    "        for trace_id in trace_ids:\n",
    "            trace_data = session_data[session_data[\"context.trace_id\"] == trace_id]\n",
    "            trace_start_times[trace_id] = trace_data[\"start_time\"].min()\n",
    "\n",
    "        # Sort trace IDs by their start times\n",
    "        ordered_trace_ids = sorted(\n",
    "            trace_start_times.keys(), key=lambda x: trace_start_times[x]\n",
    "        )\n",
    "\n",
    "        # Extract data for each column type across all traces in chronological order\n",
    "        for output_key, source_col in extract_cols.items():\n",
    "            all_trace_data = []\n",
    "\n",
    "            for trace_id in ordered_trace_ids:\n",
    "                trace_data = session_data[session_data[\"context.trace_id\"] == trace_id]\n",
    "                # Sort spans within trace by start_time\n",
    "                trace_data = trace_data.sort_values(\"start_time\")\n",
    "\n",
    "                # Aggregate values for this trace\n",
    "                trace_values = []\n",
    "                for _, row in trace_data.iterrows():\n",
    "                    value = row.get(source_col)\n",
    "                    if not filter_empty or (value is not None and value):\n",
    "                        # Truncate individual values\n",
    "                        if isinstance(value, str):\n",
    "                            value = truncate_text(value, max_chars_per_value, truncation_strategy)\n",
    "                        trace_values.append(value)\n",
    "\n",
    "                if trace_values:\n",
    "                    # Use the trace index in the ordered list as the key\n",
    "                    trace_index = ordered_trace_ids.index(trace_id) + 1\n",
    "                    all_trace_data.append({str(trace_index): trace_values})\n",
    "\n",
    "            # Use the output_key directly without adding \"session_\" prefix\n",
    "            session_dict[output_key] = all_trace_data\n",
    "\n",
    "        # Check if session exceeds max size and truncate if necessary\n",
    "        current_size = estimate_session_size(session_dict)\n",
    "        if current_size > max_chars_per_session:\n",
    "            print(f\"Warning: Session {session_id} exceeds max size ({current_size} chars). Truncating...\")\n",
    "\n",
    "            # Truncate by reducing the number of traces if we have many\n",
    "            if len(ordered_trace_ids) > 10:  # If more than 10 traces, keep first 5 and last 5\n",
    "                kept_traces = ordered_trace_ids[:5] + ordered_trace_ids[-5:]\n",
    "                for output_key in extract_cols.keys():\n",
    "                    if output_key in session_dict:\n",
    "                        # Filter to keep only the selected traces\n",
    "                        filtered_data = []\n",
    "                        for trace_data in session_dict[output_key]:\n",
    "                            trace_idx = list(trace_data.keys())[0]\n",
    "                            if int(trace_idx) <= 5 or int(trace_idx) > len(ordered_trace_ids) - 5:\n",
    "                                filtered_data.append(trace_data)\n",
    "                        session_dict[output_key] = filtered_data\n",
    "\n",
    "                # Update trace count\n",
    "                session_dict[\"trace_count\"] = len(kept_traces)\n",
    "\n",
    "            # If still too large, truncate individual values more aggressively\n",
    "            current_size = estimate_session_size(session_dict)\n",
    "            if current_size > max_chars_per_session:\n",
    "                aggressive_limit = max_chars_per_value // 2\n",
    "                for output_key in extract_cols.keys():\n",
    "                    if output_key in session_dict:\n",
    "                        for trace_data in session_dict[output_key]:\n",
    "                            for trace_idx, values in trace_data.items():\n",
    "                                if isinstance(values, list):\n",
    "                                    trace_data[trace_idx] = [\n",
    "                                        truncate_text(str(v), aggressive_limit, truncation_strategy)\n",
    "                                        if isinstance(v, str) else v\n",
    "                                        for v in values\n",
    "                                    ]\n",
    "\n",
    "        # Add to results\n",
    "        results.append(session_dict)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_calls(output_messages):\n",
    "    if not output_messages:\n",
    "        return []\n",
    "\n",
    "    tool_calls = []\n",
    "    for message in output_messages:\n",
    "        if \"message.tool_calls\" in message:\n",
    "            for tool_call in message[\"message.tool_calls\"]:\n",
    "                tool_calls.append({\n",
    "                    \"name\": tool_call[\"tool_call.function.name\"],\n",
    "                    \"arguments\": tool_call[\"tool_call.function.arguments\"]\n",
    "                })\n",
    "    return tool_calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0StKvAlpJFZ"
   },
   "source": [
    "## Evaluation Configuration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhaqMpjapJFZ"
   },
   "source": [
    "#### **Filter Data**\n",
    "\n",
    "Customize these parameters to match your specific evaluation needs:\n",
    "\n",
    "| Parameter | Description | Example |\n",
    "|-----------|-------------|---------|\n",
    "| trace_filters | Criteria for selecting traces within sessions | `{\"name\": {\"contains\": \"searchrouter\"}}` |\n",
    "| span_filters | Criteria for selecting spans within traces | `{\"parent_id\": {\"==\": None}}` |\n",
    "\n",
    "Span filters help determine which specific spans within the matched traces will be used for the evaluation. For example, filtering for `\"parent_id\": None` ensures we focus on the parent spans for the selected sessions.\n",
    "   > **Note**: Update the `trace_filters` and `span_filters` to match your specific evaluation criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(primary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of root spans (spans with no parent) in the primary dataframe\n",
    "primary_df.loc[primary_df['parent_id'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter traces to only include root spans (spans with no parent)\n",
    "# This helps focus the evaluation on top-level interactions\n",
    "eval_traces = filter_sessions_by_trace_criteria(\n",
    "    df=primary_df,\n",
    "    # trace_filters={},\n",
    "    span_filters={\"parent_id\": {\"==\": None }}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_eval_traces = eval_traces.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCaKqKp8pJFa"
   },
   "source": [
    "### Prepare the data for the evaluation\n",
    "This will group the prompt variables by session_id and extract the required columns and append any additional data to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = prepare_session_data_for_evaluation(\n",
    "    df=eval_traces,\n",
    "    extract_cols={\"output_messages\": \"attributes.output.value\", \"user_inputs\": \"attributes.input.value\"}, #can also add any additional columns to the dataframe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 2 sessions that have more than 5 traces for detailed evaluation\n",
    "sample_data = sessions_df.loc[sessions_df['trace_count'] > 5].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmjzY-FzpJFa"
   },
   "source": [
    "## Running the Evaluation\n",
    "\n",
    "After preparing your sessions and configuring the evaluation parameters, you can execute the LLM-based evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = OpenAIModel(\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails =[\"correct\",\"incorrect\"]\n",
    "eval_results = llm_classify(\n",
    "    dataframe=sessions_df,\n",
    "    template=SESSION_CORRECTNESS_PROMPT,\n",
    "    model=model,\n",
    "    rails=rails,\n",
    "    provide_explanation=True,\n",
    "    verbose=False,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI4HXeY-pJFa"
   },
   "source": [
    "   ## Analyzing Results\n",
    "   \n",
    "   The evaluation results contain:\n",
    "   - **label**: Overall trajectory assessment (correct/incorrect)\n",
    "   - **explanation**: Detailed reasoning for the assessment\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # # Set pandas options to display full content\n",
    "# pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_rows', None)     # Show all rows\n",
    "# pd.set_option('display.max_colwidth', None) # Show full column width\n",
    "# pd.set_option('display.width', None)        # Auto-detect terminal width\n",
    "# pd.set_option('display.max_seq_items', None) # Show all items in sequences\n",
    "\n",
    "\n",
    "# Reset options back to default when done\n",
    "pd.reset_option('display.max_colwidth')\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAVF1tv_pJFa"
   },
   "source": [
    "The evaluation results can then be merged with your original data for analysis or to log back to Arize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with original df to get span_id\n",
    "merged_df = pd.merge(sessions_df, eval_results, left_index=True, right_index=True)\n",
    "\n",
    "merged_df.rename(\n",
    "    columns={\n",
    "        \"label\": \"session_eval.SessionCorrectness.label\",\n",
    "        \"explanation\": \"session_eval.SessionCorrectness.explanation\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Get the root spans for each session - using the first trace's root span as the session's root span\n",
    "root_spans = primary_df[primary_df[\"parent_id\"].isnull()][\n",
    "    [\"attributes.session.id\", \"context.trace_id\", \"context.span_id\"]\n",
    "].drop_duplicates(subset=[\"attributes.session.id\"], keep=\"first\")\n",
    "\n",
    "# Merge with merged_df to get the root span_id\n",
    "final_df = pd.merge(merged_df, root_spans, on=\"attributes.session.id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eval_df = final_df[\n",
    "    [\n",
    "        \"attributes.session.id\",\n",
    "        \"context.span_id\",\n",
    "        \"session_eval.SessionCorrectness.label\",\n",
    "        \"session_eval.SessionCorrectness.explanation\",\n",
    "    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arize.pandas.logger import Client\n",
    "\n",
    "\n",
    "# Initialize Arize client using the model_id of your traces\n",
    "arize_client = Client(space_id=os.environ['ARIZE_SPACE_ID'], api_key=os.environ['ARIZE_API_KEY'])\n",
    "\n",
    "\n",
    "# Set the evals_df to have the correct span ID to log it to Arize\n",
    "final_eval_df = final_eval_df.set_index(final_df[\"context.span_id\"])\n",
    "\n",
    "# Use Arize client to log evaluations\n",
    "response = arize_client.log_evaluations_sync(\n",
    "    dataframe=final_eval_df,\n",
    "    model_id=os.environ['ARIZE_MODEL_ID'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See your results in Arize\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/docs/notebooks/session-level-evals/Screenshot%202025-06-22%20at%205.48.37%E2%80%AFPM.png\" width=\"800\"/>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
