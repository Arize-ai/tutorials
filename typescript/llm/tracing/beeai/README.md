This is a tutorial for tracing LLM calls using BeeAI. You'll need to have Ollama installed along with a Phoenix API key. 

[Signup for Phoenix Cloud here](https://app.phoenix.arize.com).
[Install Ollama with llama 3.2 here](https://ollama.com).

## Setup

This project requires Node.js v18 or later. We recommend using Node Version Manager (nvm) to manage your Node.js versions.

```bash
nvm use 20
yarn install
```

## Run

```bash
yarn start
```