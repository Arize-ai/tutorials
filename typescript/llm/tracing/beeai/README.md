This is a tutorial for tracing LLM calls using BeeAI. You'll need to have Ollama installed along with a Phoenix API key. 

[Signup for Phoenix Cloud here](https://app.phoenix.arize.com).
[Install Ollama with llama 3.2 here](https://ollama.com).

## Setup

```bash
yarn install
```

## Run

```bash
yarn start
```